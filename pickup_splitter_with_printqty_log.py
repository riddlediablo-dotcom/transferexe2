# -*- coding: utf-8 -*-
"""
å·¥å‚æè´§æ˜ç»†è¡¨è‡ªåŠ¨æ‹†åˆ†å·¥å…·ï¼ˆå¸¦UIï¼Œä¿ç•™æ¨¡æ¿å…¬å¼ï¼Œæ”¯æŒSKU/å·¥å‚é…ç½®ï¼‰

æ–°å¢/ä¿®å¤ç‚¹ï¼ˆé’ˆå¯¹ä½ è¿™æ¬¡çš„è¦æ±‚ï¼‰ï¼š
1) ä¿®å¤ Tkinter å¼‚å¸¸å¼¹çª—çš„ NameErrorï¼ˆPython 3 ä¼šæ¸…é™¤ except e å˜é‡ï¼‰
2) é…ç½®æ–‡ä»¶è¡¨å¤´æŒ‰ä½ æä¾›çš„æ ¼å¼ï¼š
   - sheet: SKUä¿¡æ¯  (SKU / SKUæ£€ç´¢ / äº§å“åç§° / å·¥å‚ç®€ç§° / ç®±è§„ / é•¿ / å®½ / é«˜ / æ¯›é‡ / æ–¹æ•°)
   - sheet: å·¥å‚ä¿¡æ¯  (å·¥å‚åç§° / å·¥å‚åœ°å€)
   è¾“å‡ºä¼šæŠŠ SKU/é•¿å®½é«˜/æ¯›é‡ å†™å…¥æ¨¡æ¿çš„ã€ŒåŒ¹é…ã€sheetï¼ˆA~Få›ºå®šç»“æ„ï¼‰
3) å·¥å‚åœ°å€æ”¯æŒâ€œæ¨¡ç³ŠåŒ¹é…â€ï¼šä¾‹å¦‚é…ç½®é‡Œå·¥å‚åç§°å«â€œæ­£ç¾â€ï¼Œæ–‡ä»¶1ä¾›åº”å•†/å·¥å‚ç®€ç§°å«â€œæ­£ç¾â€ä¹Ÿèƒ½åŒ¹é…åˆ°åœ°å€
4) UI å¢åŠ å‹¾é€‰ï¼šæ˜¯å¦æŒ‰ä¾›åº”å•†å»ºäºŒçº§æ–‡ä»¶å¤¹ï¼ˆå‹¾ä¸Š=æ‹†åˆ†åˆ°ä¾›åº”å•†æ–‡ä»¶å¤¹ï¼›ä¸å‹¾=ç›´æ¥è¾“å‡ºåˆ°åŒä¸€ç›®å½•ï¼‰
5) è¾“å‡ºè·¯å¾„è‡ªåŠ¨å»ºç«‹å­æ–‡ä»¶å¤¹ï¼š ç›´å‘+YYYY.MM.DDï¼ˆæ—¥æœŸå– UI çš„â€œé¢„è®¡æè´§æ—¥æœŸâ€ï¼‰
6) æ¨¡æ¿æ–‡ä»¶ï¼šä»ç„¶å»ºè®®é€‰æ‹©ï¼ˆä¸ºäº†ä¿ç•™å…¬å¼ï¼‰ï¼Œä½†ä½ åªéœ€è¦é€‰ä¸€æ¬¡ï¼ˆæœ‰è®°å¿†ï¼‰ã€‚
   ä¹Ÿæ”¯æŒæŠŠæ¨¡æ¿æ”¾åœ¨è„šæœ¬/EXEåŒç›®å½•ï¼Œå‘½åä¸ºï¼šå·¥å‚æè´§æ˜ç»†æ¨¡æ¿.xlsxï¼ˆå°±å¯ä»¥ä¸é€‰ï¼‰

ä¾èµ–ï¼š
    pip install pandas openpyxl playwright

æ‰“åŒ…EXEï¼ˆWindowsï¼‰ï¼š
    pyinstaller --onefile --windowed pickup_splitter_ui_V4.py
"""

import os
import re
import json
import threading
import datetime
import time
import math
from uuid import uuid4
import copy
from typing import Callable, Optional, Dict, Any, Tuple, List

import pandas as pd
import numpy as np
import openpyxl
import requests
from openpyxl.formula.translate import Translator
from tkinter import ttk, filedialog, messagebox
import tkinter as tk
from tkinter.scrolledtext import ScrolledText


CONFIG_PATH = os.path.join(os.path.expanduser("~"), ".pickup_splitter_config.json")

# ========= ç§¯åŠ  FBA ç®±å”›ï¼šæŸ¥è¯¢â†’æ‰“å°â†’ä¼ è¾“ä¸­å¿ƒä¸‹è½½ =========
BASE_URL = "https://gateway.apist.gerpgo.com"
DATA_GRID_URL = f"{BASE_URL}/supply/tms/query/shipment/dataGrid"
BATCH_PRINT_URL = f"{BASE_URL}/supply/tms/shipment/batchPrintLabels"
GET_DOWNLOAD_LIST_URL = f"{BASE_URL}/v2/download/reportDownload/getDownloadList"
GET_BATCH_FILE_URL = f"{BASE_URL}/v2/download/reportDownload/getBatchFileUrl"

USER_AGENT = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
    "(KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36 Edg/143.0.0.0"
)

ZIP_PREFIX = "FBA_SHIPMENT_"
ZIP_SUFFIX = ".zip"

# --- FBA æ‰“å°é™é¢‘ï¼ˆç§¯åŠ é¡µé¢é€šå¸¸è¦æ±‚åŒä¸€ç±»â€œæ‰“å°â€æ“ä½œé—´éš”ä¸€æ®µæ—¶é—´ï¼‰---
FBA_PRINT_COOLDOWN_DEFAULT_SEC = 35
_FBA_LAST_PRINT_TS = 0.0
_FBA_PRINT_LOCK = threading.Lock()

def _fba_wait_cooldown(cooldown_sec: int, log_cb: Optional[Callable[[str], None]] = None):
    """ç¡®ä¿ä¸¤æ¬¡ batchPrintLabels æäº¤ä¹‹é—´è‡³å°‘é—´éš” cooldown_sec ç§’ã€‚

    è¯´æ˜ï¼šç§¯åŠ å‰ç«¯é€šå¸¸ä¼šé™åˆ¶ 30s å·¦å³å†…é‡å¤ç‚¹å‡»â€œæ‰¹é‡æ‰“å°â€ï¼Œè„šæœ¬å¤ªå¿«ä¼šå¯¼è‡´åç»­è¯·æ±‚ä¸šåŠ¡å¤±è´¥ã€‚
    """
    global _FBA_LAST_PRINT_TS
    try:
        cooldown_sec = int(float(cooldown_sec))
    except Exception:
        cooldown_sec = FBA_PRINT_COOLDOWN_DEFAULT_SEC
    if cooldown_sec < 0:
        cooldown_sec = 0

    with _FBA_PRINT_LOCK:
        now = time.time()
        wait = (_FBA_LAST_PRINT_TS + cooldown_sec) - now
        if wait <= 0:
            _FBA_LAST_PRINT_TS = now
            return

        end_ts = now + wait
        last_logged = None
        while True:
            remain = end_ts - time.time()
            if remain <= 0:
                _FBA_LAST_PRINT_TS = time.time()
                return
            sec = int(math.ceil(remain))

            # æ—¥å¿—ä¸å¿…æ¯ç§’åˆ·å±ï¼šæ¯ 10 ç§’æç¤ºä¸€æ¬¡ï¼›æœ€å 3 ç§’æ¯ç§’æç¤º
            if log_cb:
                if sec <= 3 or (sec % 10 == 0):
                    if sec != last_logged:
                        last_logged = sec
                        log_cb(f"â³ ç­‰å¾… {sec}sï¼ˆç§¯åŠ æ‰“å°é™é¢‘ï¼Œé»˜è®¤ {cooldown_sec}sï¼‰â€¦")

            time.sleep(1)

def _sanitize_header_value(v: str) -> str:
    if v is None:
        return ""
    if not isinstance(v, str):
        v = str(v)
    try:
        v.encode("latin-1")
        return v
    except UnicodeEncodeError:
        from urllib.parse import quote
        return quote(v, safe=":/;?&=,%+-_.~")

def _headers(token: str, cookie: str, page_url: str, page_title_encoded: str) -> Dict[str, str]:
    h = {
        "accept": "application/json, text/plain, */*",
        "accept-language": "zh-cn",
        "content-type": "application/json",
        "origin": "https://luteos.app.gerpgo.com",
        "referer": "https://luteos.app.gerpgo.com/",
        "user-agent": USER_AGENT,
        "x-auth-token": token,
        "x-api-id": str(uuid4()),
        "x-page-id": str(uuid4()),
        "x-page-title": page_title_encoded,
        "x-page-url": page_url,
        "Cookie": cookie,
    }
    return {k: _sanitize_header_value(v) for k, v in h.items()}

def _headers_fba(token: str, cookie: str) -> Dict[str, str]:
    return _headers(token, cookie, "/amzv-app/tms/fbaShipment", "FBA%E8%B4%A7%E4%BB%B6")

def _headers_tc(token: str, cookie: str) -> Dict[str, str]:
    return _headers(token, cookie, "/amzv-app/platform/reports/transmission-center", "%E4%BC%A0%E8%BE%93%E4%B8%AD%E5%BF%83")

def _request_json(session: requests.Session, method: str, url: str, *, headers: Dict[str, str], params=None, json_body=None, timeout=30) -> Tuple[int, Any, str]:
    resp = session.request(method, url, headers=headers, params=params, json=json_body, timeout=timeout)
    text = resp.text
    try:
        j = resp.json()
    except Exception:
        j = {"_raw_text": text}
    return resp.status_code, j, text

def _extract_grid_rows(grid_json: Dict[str, Any]) -> List[Dict[str, Any]]:
    data = grid_json.get("data") or {}
    if isinstance(data, dict):
        for k in ["rows", "list", "records", "data", "result", "items"]:
            v = data.get(k)
            if isinstance(v, list) and (not v or isinstance(v[0], dict)):
                return v
    if isinstance(grid_json.get("data"), list):
        return grid_json["data"]
    return []

def _extract_download_rows(resp_json: Any) -> List[Dict[str, Any]]:
    rows: List[Dict[str, Any]] = []
    if isinstance(resp_json, dict):
        data = resp_json.get("data")
        if isinstance(data, dict):
            for k in ["list", "records", "rows", "data", "result", "items"]:
                v = data.get(k)
                if isinstance(v, list):
                    rows = v
                    break
    out = []
    for r in rows or []:
        if isinstance(r, dict) and (r.get("fileName") or r.get("filename")):
            out.append(r)
    return out

def _is_target_zip(row: Dict[str, Any]) -> bool:
    fn = (row.get("fileName") or row.get("filename") or "")
    return isinstance(fn, str) and fn.startswith(ZIP_PREFIX) and fn.lower().endswith(ZIP_SUFFIX)

def _parse_row_time(row: Dict[str, Any]) -> Optional[datetime.datetime]:
    t = row.get("requestTime") or row.get("gmtCreate") or row.get("createTime") or row.get("applyTime") or ""
    if isinstance(t, (int, float)):
        ts = t / 1000 if t > 10_000_000_000 else float(t)
        return datetime.datetime.fromtimestamp(ts)
    if isinstance(t, str) and t:
        try:
            return datetime.datetime.strptime(t[:19], "%Y-%m-%d %H:%M:%S")
        except Exception:
            return None
    return None

def read_fba_ids_from_split_xlsx(xlsx_path: str) -> List[str]:
    """ä»æ‹†åˆ†åçš„ Excelï¼ˆsheet: å·¥å‚æè´§æ˜ç»†ï¼‰è¯»å–ç”¨äºè¯·æ±‚æ‰“å°çš„ shipmentId åˆ—è¡¨ã€‚

    çº¦å®šï¼š
    - æ‹†åˆ†æ–‡ä»¶é‡Œï¼šReference ID åˆ—å­˜æ”¾â€œFBAè´§ä»¶ç¼–å·â€ï¼ˆå€¼é€šå¸¸åŒ…å«/ä»¥ FBA å¼€å¤´ï¼‰
    - ä»…å¯¹åŒ…å« 'FBA' çš„ Reference ID å‘èµ·æ‰“å°/ä¸‹è½½è¯·æ±‚ï¼ˆTF è°ƒæ‹¨å•ä¸å‚ä¸ï¼‰
    """
    try:
        df = pd.read_excel(xlsx_path, sheet_name="å·¥å‚æè´§æ˜ç»†", engine="openpyxl", dtype=str)
    except Exception:
        df = pd.read_excel(xlsx_path, sheet_name=0, engine="openpyxl", dtype=str)

    cols = [str(c).strip() for c in df.columns]
    cand = None
    for c in cols:
        if c in ("Reference ID", "Reference_ID", "reference_id", "å‚è€ƒå•å·", "ReferenceId"):
            cand = c
            break
    if not cand:
        # å…œåº•ï¼šåŒ…å« reference çš„åˆ—
        for c in cols:
            if "reference" in c.lower():
                cand = c
                break
    if not cand:
        return []

    ids = []
    for v in df[cand].fillna("").astype(str).tolist():
        s = v.strip()
        if not s:
            continue
        su = s.upper()
        if "FBA" in su:
            ids.append(su)

    seen = set()
    out = []
    for x in ids:
        if x not in seen:
            seen.add(x)
            out.append(x)
    return out

def fba_download_labels_for_file(xlsx_path: str, token: str, cookie: str, log_cb: Optional[Callable[[str], None]]=None,
                                 poll_interval_sec: int = 3, poll_timeout_sec: int = 240, lookback_sec: int = 180,
                                 cooldown_sec: int = FBA_PRINT_COOLDOWN_DEFAULT_SEC) -> Optional[str]:
    """å•æ–‡ä»¶ï¼šè¯»å–FBA ID â†’ æŸ¥è¯¢â†’æ‰“å°â†’è½®è¯¢ä¼ è¾“ä¸­å¿ƒâ†’ä¸‹è½½ZIPåˆ°åŒç›®å½•ã€‚

    ä¸»è¦ä¿®å¤ç‚¹ï¼š
    - ä¼˜å…ˆå°è¯•ä½¿ç”¨ openpyxl.load_workbook(..., data_only=True) æ¥è¯»å– sheet çš„â€œè®¡ç®—åâ€å€¼ï¼ˆå¦‚æœå•å…ƒæ ¼æ˜¯å…¬å¼ä¸” Excel å·²ä¿å­˜è®¡ç®—è¿‡çš„å€¼ï¼Œä¼šè¿”å›è®¡ç®—å€¼ï¼‰ã€‚
    - å¦‚æœ data_only è¯»å–åå‘è´§ç®±æ•°ä»ä¸ºç©ºï¼Œåˆ™å°è¯•ç”¨ å‘è´§æ•°é‡ / å•ç®±æ•°é‡ å‘ä¸Šå–æ•´ è®¡ç®—ç®±æ•°ã€‚
    - è‹¥ä»æ— æ³•è·å¾—ï¼Œåˆ™å›é€€ä½¿ç”¨ API è¿”å›çš„ cartonQuantity/boxNum/packingBoxNumï¼Œæœ€ç»ˆå›é€€ 1ã€‚
    """
    # å…ˆå°è¯•è¯»å–æ‹†åˆ†è¡¨ï¼ˆä¼˜å…ˆ sheet åç§°åŒ…å« "å·¥å‚æè´§æ˜ç»†"ï¼‰
    df = None
    workbook = None
    sheet_name_used = None
    try:
        # 1) å°è¯• openpyxl data_only æ–¹å¼è¯»å–ï¼ˆä¼˜å…ˆï¼‰
        try:
            wb = openpyxl.load_workbook(xlsx_path, data_only=True, read_only=True)
            # é€‰ sheetï¼šä¼˜å…ˆåä¸º "å·¥å‚æè´§æ˜ç»†"ï¼Œå¦åˆ™ç¬¬ä¸€ä¸ª
            sn = None
            for s in wb.sheetnames:
                if "å·¥å‚" in s or "æè´§" in s or "æ˜ç»†" in s:
                    sn = s
                    break
            if not sn:
                sn = wb.sheetnames[0]
            sheet_name_used = sn
            ws = wb[sn]
            # å°† sheet å†…å®¹è½¬ä¸º DataFrame
            data = []
            headers = []
            for i, row in enumerate(ws.iter_rows(values_only=True)):
                if i == 0:
                    headers = [str(x).strip() if x is not None else "" for x in row]
                    continue
                # ä¿è¯é•¿åº¦ä¸€è‡´
                rvals = []
                for j in range(len(headers)):
                    if j < len(row):
                        rvals.append(row[j])
                    else:
                        rvals.append(None)
                data.append(rvals)
            if headers:
                df = pd.DataFrame(data, columns=headers, dtype=str)
                workbook = wb
        except Exception:
            # å¿½ç•¥å¤±è´¥ï¼Œåç»­å°è¯• pandas è¯»å–
            df = None
            workbook = None

        # 2) å¦‚æœ openpyxl data_only æœªå¾—åˆ°æœ‰æ•ˆ DataFrameï¼Œå†ç”¨ pandas è¯»å–ï¼ˆé€šå¸¸èƒ½è¯»å–ä½† formula å¯èƒ½æ˜¯å…¬å¼æ–‡æœ¬ï¼‰
        if df is None:
            try:
                try:
                    df = pd.read_excel(xlsx_path, sheet_name="å·¥å‚æè´§æ˜ç»†", engine="openpyxl", dtype=str)
                    sheet_name_used = "å·¥å‚æè´§æ˜ç»†"
                except Exception:
                    df = pd.read_excel(xlsx_path, sheet_name=0, engine="openpyxl", dtype=str)
                    sheet_name_used = df.columns.name if df.columns.name else 0
            except Exception:
                if log_cb:
                    log_cb(f"âš ï¸ æ— æ³•è¯»å–æ‹†åˆ†æ–‡ä»¶ä»¥è·å–å‘è´§ç®±æ•°ï¼Œç¨åå°†å›é€€åˆ° API è¿”å›çš„ç®±æ•°æˆ–é»˜è®¤ 1ï¼š{xlsx_path}")
                df = None
    except Exception:
        df = None

    # å»ºç«‹ Reference ID -> å‘è´§ç®±æ•° æ˜ å°„
    id_to_qty = {}
    if df is not None and not df.empty:
        # æ ‡å‡†åŒ–åˆ—ååˆ—è¡¨
        cols = [str(c).strip() for c in df.columns]
        # å€™é€‰åˆ— (ä¼˜å…ˆçº§)
        id_col_candidates = ["Reference ID", "Reference_ID", "reference_id", "ReferenceId", "FBA ID", "FBAè´§ä»¶ç¼–å·", "FBAè´§ä»¶å·", "å‚è€ƒå•å·"]
        qty_col_candidates = ["å‘è´§ç®±æ•°", "å‘è´§ç®±", "å‘è´§ç®±æ•°é‡", "ç®±æ•°", "ç®±æ•°(å‘è´§ç®±æ•°)", "å‘è´§ç®±æ•°(J)"]
        # æŸ¥æ‰¾ id åˆ—ï¼ˆæŒ‰å€™é€‰ä¼˜å…ˆçº§ï¼‰
        id_col = None
        for cand in id_col_candidates:
            if cand in cols:
                id_col = cand
                break
        if not id_col:
            # å®½æ¾åŒ¹é…
            for c in cols:
                if "reference" in c.lower() or "fba" in c.lower() or "è´§ä»¶" in c:
                    id_col = c
                    break
        # æŸ¥æ‰¾ qty åˆ—
        qty_col = None
        for cand in qty_col_candidates:
            if cand in cols:
                qty_col = cand
                break
        if not qty_col:
            for c in cols:
                lc = c.lower()
                if "ç®±" in lc and "ç®±è§„" not in lc and "ç®±æ•°(" not in lc:
                    qty_col = c
                    break

        # æŸ¥æ‰¾å‘è´§æ•°é‡ / å•ç®±æ•°é‡ ç”¨äºè®¡ç®—
        ship_qty_cols = [c for c in cols if c in ("å‘è´§æ•°é‡", "å‘è´§æ€»æ•°", "æ•°é‡", "å‡ºè´§æ•°é‡", "total_qty", "TotalQty")]
        single_box_cols = [c for c in cols if c in ("å•ç®±æ•°é‡", "ç®±è§„", "ç®±å†…æ•°é‡", "å•ç®±æ•°", "units_per_carton", "units_per_box", "ç®±å†…æ•°é‡(æ¯ç®±)")]
        # å…œåº• heuristic
        if not ship_qty_cols:
            for c in cols:
                if "å‘è´§æ•°é‡" in c or "å‘è´§æ€»" in c or c == "å‘è´§":
                    ship_qty_cols.append(c)
        if not single_box_cols:
            for c in cols:
                if "å•ç®±" in c or "ç®±è§„" in c or "ç®±å†…" in c:
                    single_box_cols.append(c)

        # å¦‚æœ id_col ä¸ºç©ºï¼Œæ— æ³•å»ºç«‹æ˜ å°„
        if id_col:
            # éå†è¡Œå»ºç«‹æ˜ å°„
            for _, rr in df.iterrows():
                raw_id = rr.get(id_col)
                if raw_id is None:
                    continue
                raw_id_s = str(raw_id).strip()
                if not raw_id_s or raw_id_s.lower() in ("nan", "none"):
                    continue
                key = raw_id_s.upper()

                qval = None
                # 1) å°è¯•ç›´æ¥ä» qty_col è¯»å–ï¼ˆopenpyxl data_only å¯ä¼šæŠŠå…¬å¼çš„è®¡ç®—å€¼æ”¾åœ¨è¿™é‡Œï¼‰
                if qty_col and qty_col in df.columns:
                    try:
                        qraw = rr.get(qty_col)
                        if pd.notna(qraw) and str(qraw).strip() not in ("", "nan"):
                            qval = int(float(str(qraw).strip()))
                    except Exception:
                        qval = None

                # 2) å¦‚æœ qval æ— æ•ˆï¼Œå°è¯•ç”¨ å‘è´§æ•°é‡ / å•ç®±æ•°é‡ è®¡ç®—ï¼ˆå‘ä¸Šå–æ•´ï¼‰
                if (qval is None or qval <= 0) and ship_qty_cols and single_box_cols:
                    computed = None
                    for sq in ship_qty_cols:
                        for sb in single_box_cols:
                            try:
                                s_val = rr.get(sq)
                                b_val = rr.get(sb)
                                if s_val in (None, "") or b_val in (None, ""):
                                    continue
                                s_num = float(str(s_val).strip())
                                b_num = float(str(b_val).strip())
                                if b_num == 0:
                                    continue
                                computed = math.ceil(s_num / b_num)
                                if computed > 0:
                                    qval = int(computed)
                                    break
                            except Exception:
                                continue
                        if qval is not None and qval > 0:
                            break

                # 3) å°è¯•é™„è¿‘åˆ—ï¼ˆå¦‚æœæŸäº›æƒ…å†µä¸‹ qty æ”¾åœ¨ id å·¦å³ï¼‰
                if (qval is None or qval <= 0):
                    try:
                        cols_list = cols
                        id_idx = cols_list.index(id_col)
                        for offset in (1, -1, 2, -2, 3):
                            idx = id_idx + offset
                            if 0 <= idx < len(cols_list):
                                cand = cols_list[idx]
                                try:
                                    qraw = rr.get(cand)
                                    if pd.notna(qraw) and str(qraw).strip() not in ("", "nan"):
                                        qval = int(float(str(qraw).strip()))
                                        break
                                except Exception:
                                    continue
                    except Exception:
                        pass

                # å…œåº•ä¸º 1
                if qval is None or (isinstance(qval, (int, float)) and qval <= 0):
                    qval = 1

                id_to_qty[key] = int(qval)

    # è¯»å– FBA IDsï¼ˆä¿ç•™åŸé¡¹ç›®çš„ read_fba_ids_from_split_xlsx å‡½æ•°ï¼‰
    fba_ids = read_fba_ids_from_split_xlsx(xlsx_path)
    if not fba_ids:
        if log_cb:
            log_cb(f"â„¹ï¸ æœªå‘ç°FBA IDï¼Œè·³è¿‡ç®±å”›ï¼š{os.path.basename(xlsx_path)}")
        return None

    sess = requests.Session()
    payload = {"__inner_refresh": True, "sort": "id", "order": "descend", "shipmentIdList": fba_ids, "type": "FBA", "page": 1, "pagesize": 200}
    st, j, raw = _request_json(sess, "POST", DATA_GRID_URL, headers=_headers_fba(token, cookie), json_body=payload, timeout=30)
    if st < 200 or st >= 300:
        raise RuntimeError(f"FBAæŸ¥è¯¢å¤±è´¥ HTTP={st}ï¼š{raw[:300]}")
    rows = _extract_grid_rows(j)

    wanted = set([x.upper() for x in fba_ids])
    tasks = []
    for r in rows:
        if not isinstance(r, dict):
            continue
        sid = r.get("shipmentId") or r.get("shipmentID") or r.get("shipment_id") or r.get("shipmentNo")
        if sid is None:
            continue
        sid_key = str(sid).upper().strip()
        if sid_key not in wanted:
            # å…¼å®¹å¤§å°å†™å·®å¼‚
            if sid_key not in wanted:
                continue
        internal_id = r.get("id")

        # ä¼˜å…ˆä½¿ç”¨æ‹†åˆ†æ–‡ä»¶æ˜ å°„çš„å‘è´§ç®±æ•°
        qty = None
        if id_to_qty and sid_key in id_to_qty:
            qty = id_to_qty[sid_key]
        else:
            # å›é€€ä½¿ç”¨ API è¿”å›çš„å­—æ®µ
            qty = r.get("cartonQuantity") or r.get("boxNum") or r.get("packingBoxNum") or r.get("cartonNum") or r.get("carton_count") or 1
            try:
                qty = max(1, int(str(qty).strip()))
            except Exception:
                qty = 1

        base_task = {
            "printQuantity": qty,
            "pageType": "PackageLabel_Thermal_100_100",
            "printType": "Package",
            "hideShipFrom": False,
            "hideShipTo": False,
            "reorderFlag": False,
            "waterMarkFlag": False,
            "productNameFlag": False,
            "waterMarkTemplateId": "",
        }
        if log_cb:
            log_cb(f"ğŸ§¾ FBA {sid_key} â†’ æ‰“å°ç®±æ•° print qty = {qty}")

        if internal_id is not None:
            tasks.append({"id": internal_id, **base_task})
        else:
            tasks.append({"shipmentNo": sid, **base_task})

    if not tasks:
        raise RuntimeError("FBAæŸ¥è¯¢æœ‰è¿”å›ï¼Œä½†æœªåŒ¹é…åˆ°å¯æ‰“å°ä»»åŠ¡ï¼ˆè¯·æ£€æŸ¥shipmentIdæ˜¯å¦å­˜åœ¨/ä¸€è‡´ï¼‰")

    _fba_wait_cooldown(cooldown_sec, log_cb=log_cb)

    submit_time = datetime.datetime.now()
    st, _, raw2 = _request_json(sess, "POST", BATCH_PRINT_URL, headers=_headers_fba(token, cookie), json_body=tasks, timeout=60)
    if st not in (200, 203):
        raise RuntimeError(f"æäº¤æ‰“å°å¤±è´¥ HTTP={st}ï¼š{raw2[:300]}")
    if log_cb:
        log_cb(f"ğŸ–¨ï¸ å·²æäº¤FBAç®±å”›æ‰“å°ï¼š{os.path.basename(xlsx_path)}ï¼ˆ{len(tasks)} ä¸ªä»»åŠ¡ï¼‰")

    start_day = (submit_time - datetime.timedelta(days=1)).date()
    end_day = datetime.datetime.now().date()
    params = {"order":"", "page":1, "pagesize":50, "startDate": start_day.strftime("%Y-%m-%d"), "endDate": end_day.strftime("%Y-%m-%d"), "dateType": 1}

    st, base_json, rawb = _request_json(sess, "GET", GET_DOWNLOAD_LIST_URL, headers=_headers_tc(token, cookie), params=params, timeout=30)
    if st < 200 or st >= 300:
        raise RuntimeError(f"è·å–ä¸‹è½½åˆ—è¡¨å¤±è´¥ï¼ˆåŸºçº¿ï¼‰ HTTP={st}: {rawb[:200]}")
    base_ids = {str(r.get("id")) for r in _extract_download_rows(base_json) if r.get("id") is not None}

    earliest = submit_time - datetime.timedelta(seconds=lookback_sec)
    deadline = time.time() + poll_timeout_sec
    picked = None

    while time.time() < deadline:
        st, cur_json, rawc = _request_json(sess, "GET", GET_DOWNLOAD_LIST_URL, headers=_headers_tc(token, cookie), params=params, timeout=30)
        if st < 200 or st >= 300:
            raise RuntimeError(f"è·å–ä¸‹è½½åˆ—è¡¨å¤±è´¥ HTTP={st}: {rawc[:200]}")
        rows = _extract_download_rows(cur_json)
        candidates = []
        for r in rows:
            if r.get("id") is None:
                continue
            if str(r.get("id")) in base_ids:
                continue
            if not _is_target_zip(r):
                continue
            rt = _parse_row_time(r)
            if rt and rt < earliest:
                continue
            candidates.append(r)
        if candidates:
            candidates.sort(key=lambda x: int(x.get("id") or 0), reverse=True)
            picked = candidates[0]
            break
        time.sleep(max(1, poll_interval_sec))

    if not picked:
        raise TimeoutError("ç­‰å¾…ä¸‹è½½ZIPè¶…æ—¶ï¼ˆä¼ è¾“ä¸­å¿ƒæœªå‡ºç°æœ¬æ¬¡æ–°å¢FBA_SHIPMENT_*.zipï¼‰")

    file_id = picked.get("id")
    file_name = picked.get("fileName") or picked.get("filename")
    st, j3, raw3 = _request_json(sess, "POST", GET_BATCH_FILE_URL, headers=_headers_tc(token, cookie),
                                json_body=[{"id": file_id, "fileName": file_name}], timeout=30)
    if st < 200 or st >= 300:
        raise RuntimeError(f"è·å–ä¸‹è½½URLå¤±è´¥ HTTP={st}ï¼š{raw3[:300]}")
    dl_url = j3.get("data") if isinstance(j3, dict) else None
    if not dl_url:
        raise RuntimeError("ä¸‹è½½URLè¿”å›ä¸ºç©º")

    out_dir = os.path.dirname(os.path.abspath(xlsx_path))
    out_zip = os.path.join(out_dir, file_name)

    with sess.get(dl_url, headers={"user-agent": USER_AGENT}, stream=True, timeout=180) as r:
        r.raise_for_status()
        with open(out_zip, "wb") as f:
            for chunk in r.iter_content(chunk_size=1024*256):
                if chunk:
                    f.write(chunk)

    if log_cb:
        log_cb(f"âœ… ç®±å”›ZIPä¸‹è½½å®Œæˆï¼š{out_zip}")
    return out_zip


def auto_login_get_token_cookie(account: str, password: str, log_cb: Optional[Callable[[str], None]]=None) -> Tuple[str, str]:
    """å¯é€‰ï¼šPlaywright è‡ªåŠ¨ç™»å½•è·å– token/cookieï¼ˆè‹¥å¤±è´¥å¯å›é€€æ‰‹åŠ¨ç²˜è´´ï¼‰ã€‚"""
    try:
        from playwright.sync_api import sync_playwright
    except Exception:
        raise RuntimeError("æœªå®‰è£… playwrightï¼šè¯¥EXEéœ€è¦å†…ç½® playwrightï¼ˆæ‰“åŒ…ç¯å¢ƒ requirements.txt åŠ  playwright å¹¶ç”¨ PyInstaller --collect-all playwright é‡æ–°æ‰“åŒ…ï¼‰")

    login_url = "https://luteos.app.gerpgo.com/"
    token = ""
    cookie = ""

    with sync_playwright() as p:
        # ä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿå·²å®‰è£…çš„ Chromeï¼ˆé¿å…è¦æ±‚ playwright install ä¸‹è½½æµè§ˆå™¨ï¼‰
        try:
            browser = p.chromium.launch(channel="chrome", headless=False)
        except Exception:
            # å…œåº•ï¼šéƒ¨åˆ†ç”µè„‘å¯èƒ½æ²¡æœ‰ Chromeï¼Œä½†ä¸€å®šæœ‰ Edge
            browser = p.chromium.launch(channel="msedge", headless=False)
        context = browser.new_context()
        page = context.new_page()
        page.goto(login_url, wait_until="domcontentloaded")
        page.wait_for_timeout(1200)

        user_selectors = [
            'input[placeholder*="è´¦å·"]',
            'input[placeholder*="ç”¨æˆ·å"]',
            'input[placeholder*="æ‰‹æœº"]',
            'input[type="text"]',
        ]
        pwd_selectors = [
            'input[type="password"]',
            'input[placeholder*="å¯†ç "]',
        ]
        btn_selectors = [
            'button:has-text("ç™»å½•")',
            'button:has-text("ç™» å½•")',
            'button[type="submit"]',
        ]

        def fill_first(selectors, value) -> bool:
            for sel in selectors:
                try:
                    el = page.query_selector(sel)
                    if el:
                        el.fill(value)
                        return True
                except Exception:
                    continue
            return False

        def click_first(selectors) -> bool:
            for sel in selectors:
                try:
                    el = page.query_selector(sel)
                    if el:
                        el.click()
                        return True
                except Exception:
                    continue
            return False

        if log_cb:
            log_cb("ğŸŒ æ­£åœ¨è‡ªåŠ¨ç™»å½•è·å– token/cookie ...")
        if not fill_first(user_selectors, account) or not fill_first(pwd_selectors, password):
            browser.close()
            raise RuntimeError("è‡ªåŠ¨ç™»å½•å¤±è´¥ï¼šæœªæ‰¾åˆ°è´¦å·/å¯†ç è¾“å…¥æ¡†ï¼ˆå¯èƒ½éœ€è¦è°ƒæ•´é€‰æ‹©å™¨ï¼‰")
        if not click_first(btn_selectors):
            browser.close()
            raise RuntimeError("è‡ªåŠ¨ç™»å½•å¤±è´¥ï¼šæœªæ‰¾åˆ°ç™»å½•æŒ‰é’®ï¼ˆå¯èƒ½éœ€è¦è°ƒæ•´é€‰æ‹©å™¨ï¼‰")

        page.wait_for_timeout(6000)

        try:
            token = page.evaluate("() => window.localStorage.getItem('x-auth-token') || window.localStorage.getItem('token') || ''")
        except Exception:
            token = ""

        ck = context.cookies()
        cookie = "; ".join([f"{c['name']}={c['value']}" for c in ck if c.get("name") and c.get("value")])
        browser.close()

    if not cookie:
        raise RuntimeError("è‡ªåŠ¨ç™»å½•æœªè·å–åˆ° cookie")
    return token, cookie

DEFAULT_TEMPLATE_NAME = "å·¥å‚æè´§æ˜ç»†æ¨¡æ¿.xlsx"


# ========= å·¥å…· =========
def sanitize_filename(s: str, replacement: str = "_") -> str:
    if s is None:
        return ""
    s = str(s).strip()
    s = re.sub(r'[\\/:*?"<>|\r\n]+', replacement, s)
    s = re.sub(r"\s+", " ", s).strip()
    return s


def parse_date(date_str: str) -> Tuple[str, str]:
    """
    è¾“å…¥ï¼š2025-12-13 / 2025/12/13 / 2025.12.13 / 2025å¹´12æœˆ13æ—¥
    è¾“å‡ºï¼š(å†™å…¥å•å…ƒæ ¼çš„æ ¼å¼ YYYY/MM/DD, æ–‡ä»¶åæ ¼å¼ YYYY.MM.DD)
    """
    s = str(date_str).strip()
    s = s.replace("å¹´", "-").replace("æœˆ", "-").replace("æ—¥", "")
    s = re.sub(r"[./]", "-", s)
    parts = [p for p in s.split("-") if p]
    if len(parts) < 3 or len(parts[0]) != 4:
        raise ValueError("æ—¥æœŸæ ¼å¼è¯·ç”¨ YYYY-MM-DD æˆ– YYYY/MM/DD æˆ– YYYY.MM.DDï¼ˆä¾‹å¦‚ 2025/12/13ï¼‰")
    y, m, d = map(int, parts[:3])
    dt = datetime.date(y, m, d)
    return dt.strftime("%Y/%m/%d"), dt.strftime("%Y.%m.%d")



def export_mid_warehouse_keep_format(
    src_xlsx: str,
    sheet_name: str,
    header_row_1based: int,
    out_xlsx: str,
    log_cb=None,
):
    """å¯¼å‡ºâ€œä¸­ä»“/éå·¥å‚ç›´å‘â€çš„æ±‡æ€»æ–‡ä»¶ï¼Œå°½é‡ä¿æŒä¸æºæ–‡ä»¶ä¸€è‡´çš„æ ¼å¼ï¼š
    - ä¿ç•™æºè¡¨å¤´ä¹‹å‰çš„æ‰€æœ‰è¡Œï¼ˆå«åˆå¹¶å•å…ƒæ ¼ã€åˆ—å®½ã€è¡Œé«˜ã€æ ·å¼ï¼‰
    - ä¿ç•™è¡¨å¤´è¡Œæ ·å¼
    - ä»…ä¿ç•™æ»¡è¶³æ¡ä»¶çš„æ•°æ®è¡Œï¼ˆæ ·å¼ä¹Ÿä¸€å¹¶å¤åˆ¶ï¼‰
    æ¡ä»¶ï¼š
      1) â€œå‘è¿ç±»å‹/ç›´å‘ç±»å‹â€ç­‰åˆ—ä¸åŒ…å«â€œå·¥å‚ç›´å‘â€
      2) æ¸ é“åˆ—åŒ…å« Amazonï¼ˆamazon/äºšé©¬é€Š/amzï¼‰
    """
    wb = openpyxl.load_workbook(src_xlsx)
    if sheet_name not in wb.sheetnames:
        sheet_name = wb.sheetnames[0]
    ws = wb[sheet_name]

    # æ‰¾è¡¨å¤´è¡Œ
    hr = header_row_1based
    # è¯»å–è¡¨å¤´
    headers = []
    for c in range(1, ws.max_column + 1):
        v = ws.cell(hr, c).value
        headers.append(str(v).strip() if v is not None else "")

    def _find_col_idx(candidates):
        cands = [x.lower() for x in candidates]
        for i, h in enumerate(headers, start=1):
            hl = (h or "").strip().lower()
            if hl in cands:
                return i
        # é€€è€Œæ±‚å…¶æ¬¡ï¼šåŒ…å«åŒ¹é…ï¼ˆä½†ä»…ç”¨äºéIDç±»å­—æ®µï¼‰
        for i, h in enumerate(headers, start=1):
            hl = (h or "").strip().lower()
            for pat in cands:
                if pat and pat in hl:
                    return i
        return None

    direct_idx = _find_col_idx(["ç›´å‘", "å‘è¿ç±»å‹", "ç›´å‘ç±»å‹", "é…é€æ–¹å¼", "å‘è´§æ–¹å¼"])
    channel_idx = _find_col_idx(["æ¸ é“", "å¹³å°", "ç«™ç‚¹", "æ¸ é“åç§°", "æ¸ é“ç±»å‹", "é”€å”®æ¸ é“"])

    # å¦‚æœç¼ºåˆ—ï¼Œå°±é€€åŒ–æˆåŸæ¥çš„ df_non.to_excelï¼ˆä¸é˜»æ–­ä¸»æµç¨‹ï¼‰
    if direct_idx is None or channel_idx is None:
        if log_cb:
            log_cb("âš ï¸ ä¸­ä»“æ±‡æ€»ï¼šæœªæ‰¾åˆ°â€œå‘è¿ç±»å‹/æ¸ é“â€åˆ—ï¼Œæ”¹ç”¨ç®€åŒ–å¯¼å‡ºï¼ˆå¯èƒ½ä¸ä¿ç•™æ ¼å¼ï¼‰ã€‚")
        df_tmp = pd.read_excel(src_xlsx, sheet_name=sheet_name, header=hr - 1, engine="openpyxl")
        df_tmp.to_excel(out_xlsx, index=False, engine="openpyxl")
        return

    # æ–°å»ºè¾“å‡ºå·¥ä½œç°¿
    out_wb = openpyxl.Workbook()
    out_ws = out_wb.active
    out_ws.title = ws.title

    # å¤åˆ¶åˆ—å®½
    for col_letter, dim in ws.column_dimensions.items():
        out_ws.column_dimensions[col_letter].width = dim.width

    # å¤åˆ¶åˆå¹¶å•å…ƒæ ¼ï¼ˆå…ˆå¤åˆ¶æ‰€æœ‰åˆå¹¶ä¿¡æ¯ï¼‰
    for mr in ws.merged_cells.ranges:
        out_ws.merge_cells(str(mr))

    # å¤åˆ¶å†»ç»“çª—æ ¼/ç­›é€‰ç­‰ï¼ˆå°½é‡ï¼‰
    out_ws.freeze_panes = ws.freeze_panes
    if ws.auto_filter and ws.auto_filter.ref:
        out_ws.auto_filter.ref = ws.auto_filter.ref

    # å¤åˆ¶ï¼šè¡¨å¤´ä¹‹å‰è¡Œ + è¡¨å¤´è¡Œ
    max_col = ws.max_column
    def _copy_cell(src_cell, dst_cell):
        dst_cell.value = src_cell.value
        if src_cell.has_style:
            dst_cell._style = copy.copy(src_cell._style)
        dst_cell.number_format = src_cell.number_format
        dst_cell.font = copy.copy(src_cell.font)
        dst_cell.fill = copy.copy(src_cell.fill)
        dst_cell.border = copy.copy(src_cell.border)
        dst_cell.alignment = copy.copy(src_cell.alignment)
        dst_cell.protection = copy.copy(src_cell.protection)
        dst_cell.comment = src_cell.comment

    for r in range(1, hr + 1):
        out_ws.row_dimensions[r].height = ws.row_dimensions[r].height
        for c in range(1, max_col + 1):
            _copy_cell(ws.cell(r, c), out_ws.cell(r, c))

    out_row = hr + 1

    # è¿‡æ»¤å¹¶å¤åˆ¶æ•°æ®è¡Œï¼ˆæ ·å¼ä¿ç•™ï¼‰
    for r in range(hr + 1, ws.max_row + 1):
        direct_val = ws.cell(r, direct_idx).value
        direct_str = str(direct_val).replace(" ", "").replace("\u3000", "") if direct_val is not None else ""
        if "å·¥å‚ç›´å‘" in direct_str:
            continue

        ch_val = ws.cell(r, channel_idx).value
        ch_str = str(ch_val).lower() if ch_val is not None else ""
        if not (("amazon" in ch_str) or ("äºšé©¬é€Š" in ch_str) or ("amz" in ch_str)):
            continue

        out_ws.row_dimensions[out_row].height = ws.row_dimensions[r].height
        for c in range(1, max_col + 1):
            _copy_cell(ws.cell(r, c), out_ws.cell(out_row, c))
        out_row += 1

    out_wb.save(out_xlsx)


def detect_sheet_and_header_row(xlsx_path: str) -> Tuple[str, int]:
    """
    è‡ªåŠ¨åœ¨å‰50è¡Œé‡Œæ‰¾åŒ…å«â€œä¸­ä»“â€å’Œâ€œç›´å‘â€çš„è¡¨å¤´è¡Œï¼Œè¿”å› (sheet_name, header_row_index_1based)
    æ‰¾ä¸åˆ°åˆ™é»˜è®¤ç¬¬ä¸€ä¸ªsheetç¬¬1è¡Œ
    """
    wb = openpyxl.load_workbook(xlsx_path, read_only=True, data_only=True)
    for sh in wb.worksheets:
        maxrow = min(sh.max_row, 50)
        maxcol = min(sh.max_column, 80)
        for r in range(1, maxrow + 1):
            texts = []
            for c in range(1, maxcol + 1):
                v = sh.cell(r, c).value
                if isinstance(v, str):
                    texts.append(v.strip())
            if any(("ä¸­ä»“" in t and "ç›´å‘" in t) for t in texts):
                return sh.title, r
    return wb.sheetnames[0], 1


def find_col(columns, candidates: List[str]) -> Optional[str]:
    cols = [str(c).strip() for c in columns]
    for pat in candidates:
        for c in cols:
            if c == pat:
                return c
    for pat in candidates:
        for c in cols:
            if pat in c:
                return c
    return None


def find_col_exact(columns, candidates: List[str]) -> Optional[str]:
    """åªåšç²¾ç¡®åˆ—ååŒ¹é…ï¼ˆé¿å…æŠŠâ€œå‘FBAæ•°é‡â€è¯¯å½“æˆIDåˆ—ï¼‰ã€‚"""
    cols = [str(c).strip() for c in columns]
    for pat in candidates:
        for c in cols:
            if c == pat:
                return c
    return None


def choose_best_numeric_col(df: pd.DataFrame, base_name: str) -> Optional[str]:
    cand = [c for c in df.columns if str(c).strip() == base_name or str(c).startswith(base_name + ".")]
    best = None
    best_nonnull = -1
    for c in cand:
        s = pd.to_numeric(df[c], errors="coerce")
        nn = int(s.notna().sum())
        if nn > best_nonnull:
            best = c
            best_nonnull = nn
    return best


def supplier_short_name(s: str) -> str:
    if s is None:
        return "æœªçŸ¥ä¾›åº”å•†"
    x = str(s).strip()
    x = re.sub(r'(æœ‰é™è´£ä»»å…¬å¸|è‚¡ä»½æœ‰é™å…¬å¸|æœ‰é™å…¬å¸|å®ä¸šæœ‰é™å…¬å¸|å®ä¸š|ç§‘æŠ€æœ‰é™å…¬å¸|ç§‘æŠ€|ç”µå™¨æœ‰é™å…¬å¸|ç”µå™¨|æ™ºèƒ½ç”µå™¨æœ‰é™å…¬å¸|æ™ºèƒ½|ç”Ÿç‰©ç§‘æŠ€æœ‰é™å…¬å¸|ç”Ÿç‰©ç§‘æŠ€|ç”µå­æœ‰é™å…¬å¸|ç”µå­|åˆ¶é€ æœ‰é™å…¬å¸|åˆ¶é€ |è´¸æ˜“æœ‰é™å…¬å¸|è´¸æ˜“)$', "", x)
    x = x.strip()
    # å»æ‰å¸¸è§åœ°åŸŸå‰ç¼€ï¼ˆå¦‚ï¼šä¸­å±±å¸‚/æ·±åœ³å¸‚/å¹¿ä¸œçœç­‰ï¼‰ï¼Œé¿å…æ–‡ä»¶å¤¹åè¿‡é•¿
    x = re.sub(r'^(?:[\u4e00-\u9fff]{2,7}(?:çœ|å¸‚|è‡ªæ²»åŒº|è‡ªæ²»å·|åœ°åŒº|ç›Ÿ|å·|å¿|åŒº))', '', x)
    x = x.strip()
    # å°½é‡ä¿ç•™ 2~6 ä¸ªä¸­æ–‡ä½œä¸ºâ€œçŸ­åâ€
    chs = re.findall(r'[\u4e00-\u9fff]+', x)
    if chs:
        t = chs[-1]
        if len(t) > 6:
            t = t[-6:]
        return sanitize_filename(t)
    return sanitize_filename(x[:10])


def norm_key(s: Any) -> str:
    if s is None:
        return ""
    x = str(s).strip()
    x = x.replace(" ", "").replace("\u3000", "")
    x = re.sub(r'[ï¼ˆï¼‰()ã€ã€‘\[\]{}<>ã€Šã€‹â€œâ€"\'`Â·â€¢,ï¼Œ.ã€‚:ï¼š;ï¼›\-_â€”/\\|]+', "", x)
    x = re.sub(r'(æœ‰é™è´£ä»»å…¬å¸|è‚¡ä»½æœ‰é™å…¬å¸|æœ‰é™å…¬å¸|å®ä¸šæœ‰é™å…¬å¸|å®ä¸š|ç§‘æŠ€æœ‰é™å…¬å¸|ç§‘æŠ€|ç”µå™¨æœ‰é™å…¬å¸|ç”µå™¨|æ™ºèƒ½ç”µå™¨æœ‰é™å…¬å¸|æ™ºèƒ½|ç”Ÿç‰©ç§‘æŠ€æœ‰é™å…¬å¸|ç”Ÿç‰©ç§‘æŠ€|ç”µå­æœ‰é™å…¬å¸|ç”µå­|åˆ¶é€ æœ‰é™å…¬å¸|åˆ¶é€ |è´¸æ˜“æœ‰é™å…¬å¸|è´¸æ˜“)$', "", x)
    return x

def norm_id_value(v: Any) -> str:
    """æŠŠå•å…ƒæ ¼å€¼è§„èŒƒä¸ºå¯ç”¨çš„å­—ç¬¦ä¸²IDï¼›None/NaN/ç©ºç™½éƒ½è¿”å›ç©ºä¸²ã€‚"""
    if v is None:
        return ""
    try:
        # pandas çš„ NaN / NaT
        if pd.isna(v):
            return ""
    except Exception:
        pass
    s = str(v).strip()
    if not s or s.lower() == "nan":
        return ""
    return s


def pick_first_id(*vals: Any) -> str:
    """æŒ‰é¡ºåºå–ç¬¬ä¸€ä¸ªéç©ºIDï¼ˆä¼˜å…ˆFBAï¼Œå…¶æ¬¡TFï¼‰ã€‚"""
    for v in vals:
        s = norm_id_value(v)
        if s:
            return s
    return ""




# ========= è¯»å–é…ç½®ï¼ˆæŒ‰ä½ ä¸Šä¼ çš„è¡¨å¤´ï¼‰ =========
def load_config_xlsx(cfg_path: str) -> Tuple[pd.DataFrame, Dict[str, str], Dict[str, str]]:
    """
    è¿”å›ï¼š
      sku_cfg_dfï¼šç”¨äºå†™å…¥æ¨¡æ¿ã€ŒåŒ¹é…ã€sheetï¼Œå­—æ®µè‡³å°‘å«ï¼š
        SKU, äº§å“åç§°, é•¿, å®½, é«˜, å•ç®±æ¯›é‡, å•ç®±æ•°é‡
      sku_factory_shortï¼šSKU -> å·¥å‚ç®€ç§°
      factory_name_to_addrï¼šå·¥å‚åç§° -> å·¥å‚åœ°å€
    """
    xls = pd.read_excel(cfg_path, sheet_name=None, engine="openpyxl")

    if "SKUä¿¡æ¯" not in xls:
        raise ValueError("é…ç½®æ–‡ä»¶ç¼ºå°‘ sheetï¼šSKUä¿¡æ¯")
    df_sku = xls["SKUä¿¡æ¯"].copy()
    df_sku.columns = [str(c).strip() for c in df_sku.columns]

    # å¿…è¦åˆ—ï¼ˆæŒ‰ä½ ç»™çš„è¡¨å¤´ï¼‰
    sku_col = find_col(df_sku.columns, ["SKU"])
    sku_search_col = find_col(df_sku.columns, ["SKUæ£€ç´¢"])
    name_col = find_col(df_sku.columns, ["äº§å“åç§°"])
    fac_short_col = find_col(df_sku.columns, ["å·¥å‚ç®€ç§°"])
    carton_col = find_col(df_sku.columns, ["ç®±è§„"])
    l_col = find_col(df_sku.columns, ["é•¿"])
    w_col = find_col(df_sku.columns, ["å®½"])
    h_col = find_col(df_sku.columns, ["é«˜"])
    gw_col = find_col(df_sku.columns, ["æ¯›é‡"])

    if sku_col is None:
        raise ValueError("é…ç½®æ–‡ä»¶ SKUä¿¡æ¯ ç¼ºå°‘åˆ—ï¼šSKU")

    rows = []
    sku_factory_short: Dict[str, str] = {}

    for _, r in df_sku.iterrows():
        sku = str(r.get(sku_col)).strip() if r.get(sku_col) is not None else ""
        if not sku or sku.lower() in ("nan", "none"):
            continue

        row = {
            "SKU": sku,
            "äº§å“åç§°": str(r.get(name_col)).strip() if name_col and r.get(name_col) is not None else "",
            "é•¿": pd.to_numeric(r.get(l_col), errors="coerce") if l_col else np.nan,
            "å®½": pd.to_numeric(r.get(w_col), errors="coerce") if w_col else np.nan,
            "é«˜": pd.to_numeric(r.get(h_col), errors="coerce") if h_col else np.nan,
            "å•ç®±æ¯›é‡": pd.to_numeric(r.get(gw_col), errors="coerce") if gw_col else np.nan,
            "å•ç®±æ•°é‡": pd.to_numeric(r.get(carton_col), errors="coerce") if carton_col else np.nan,
        }
        rows.append(row)

        if fac_short_col:
            fs = str(r.get(fac_short_col)).strip() if r.get(fac_short_col) is not None else ""
            if fs and fs.lower() not in ("nan", "none"):
                sku_factory_short[sku] = fs

        # å…¼å®¹ï¼šå¦‚æœ SKUæ£€ç´¢ å’Œ SKU ä¸åŒï¼Œä¹Ÿå†™ä¸€è¡Œâ€œåˆ«åâ€ï¼Œé˜²æ­¢æ–‡ä»¶1ç”¨çš„æ˜¯ SKUæ£€ç´¢
        if sku_search_col:
            alias = str(r.get(sku_search_col)).strip() if r.get(sku_search_col) is not None else ""
            if alias and alias.lower() not in ("nan", "none") and alias != sku:
                alias_row = row.copy()
                alias_row["SKU"] = alias
                rows.append(alias_row)
                if fac_short_col and sku in sku_factory_short:
                    sku_factory_short[alias] = sku_factory_short[sku]

    sku_cfg_df = pd.DataFrame(rows, columns=["SKU", "äº§å“åç§°", "é•¿", "å®½", "é«˜", "å•ç®±æ¯›é‡", "å•ç®±æ•°é‡"]).drop_duplicates(subset=["SKU"], keep="last")

    # å·¥å‚ä¿¡æ¯è¡¨
    factory_name_to_addr: Dict[str, str] = {}
    if "å·¥å‚ä¿¡æ¯" in xls:
        df_f = xls["å·¥å‚ä¿¡æ¯"].copy()
        df_f.columns = [str(c).strip() for c in df_f.columns]
        n_col = find_col(df_f.columns, ["å·¥å‚åç§°"])
        a_col = find_col(df_f.columns, ["å·¥å‚åœ°å€"])
        if n_col and a_col:
            for _, r in df_f.iterrows():
                n = str(r.get(n_col)).strip() if r.get(n_col) is not None else ""
                a = str(r.get(a_col)).strip() if r.get(a_col) is not None else ""
                if n and a and n.lower() not in ("nan", "none") and a.lower() not in ("nan", "none"):
                    factory_name_to_addr[n] = a

    return sku_cfg_df, sku_factory_short, factory_name_to_addr


def merge_missing_skus_from_file1(sku_cfg_df: pd.DataFrame, df1: pd.DataFrame) -> pd.DataFrame:
    sku_col = find_col(df1.columns, ["ä»“åº“SKU", "SKU"])
    name_col = find_col(df1.columns, ["äº§å“åç§°", "å“å"])
    if sku_col is None:
        return sku_cfg_df

    existing = set(sku_cfg_df["SKU"].astype(str).tolist()) if not sku_cfg_df.empty else set()
    add_rows = []
    for _, r in df1.iterrows():
        sku = str(r.get(sku_col)).strip() if r.get(sku_col) is not None else ""
        if not sku or sku.lower() in ("nan", "none"):
            continue
        if sku in existing:
            continue
        add_rows.append({
            "SKU": sku,
            "äº§å“åç§°": str(r.get(name_col)).strip() if name_col and r.get(name_col) is not None else "",
            "é•¿": np.nan,
            "å®½": np.nan,
            "é«˜": np.nan,
            "å•ç®±æ¯›é‡": np.nan,
            "å•ç®±æ•°é‡": np.nan,
        })
        existing.add(sku)

    if add_rows:
        sku_cfg_df = pd.concat([sku_cfg_df, pd.DataFrame(add_rows)], ignore_index=True)

    return sku_cfg_df


def fuzzy_factory_address(keys: List[str], factory_name_to_addr: Dict[str, str]) -> str:
    """
    keysï¼šæ¯”å¦‚ [å·¥å‚ç®€ç§°, ä¾›åº”å•†çŸ­å, ä¾›åº”å•†å…¨å]
    è¿”å›ï¼šåŒ¹é…åˆ°çš„å·¥å‚åœ°å€ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ…å«ï¼‰
    """
    if not factory_name_to_addr:
        return ""

    # é¢„å¤„ç†
    fac_items = [(k, norm_key(k), v) for k, v in factory_name_to_addr.items()]
    best = ("", 0, "")  # name, score, addr

    for key in keys:
        nk = norm_key(key)
        if not nk or len(nk) < 2:
            continue
        for orig_name, nn, addr in fac_items:
            score = 0
            if nk in nn:
                score = len(nk)
            elif nn in nk:
                score = len(nn)
            if score > best[1]:
                best = (orig_name, score, addr)

    return best[2] if best[1] > 0 else ""


def fuzzy_factory_name(keys: List[str], factory_name_to_addr: Dict[str, str]) -> str:
    """
    keysï¼šæ¯”å¦‚ [å·¥å‚ç®€ç§°, ä¾›åº”å•†çŸ­å, ä¾›åº”å•†å…¨å]
    è¿”å›ï¼šåŒ¹é…åˆ°çš„â€œå·¥å‚åç§°â€ï¼ˆé…ç½®è¡¨é‡Œçš„åå­—ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ…å«ï¼‰
    """
    if not factory_name_to_addr:
        return ""

    fac_items = [(k, norm_key(k), v) for k, v in factory_name_to_addr.items()]
    best = ("", 0)  # name, score

    for key in keys:
        nk = norm_key(key)
        if not nk or len(nk) < 2:
            continue

        for orig_name, nn, _addr in fac_items:
            score = 0
            if nk == nn:
                score = 1000 + len(nk)
            elif nk in nn:
                score = len(nk)
            elif nn in nk:
                score = len(nn)
            if score > best[1]:
                best = (orig_name, score)

    return best[0] if best[1] > 0 else ""



# ========= æ¨¡æ¿å†™å…¥ï¼ˆä¿ç•™å…¬å¼ï¼‰ =========
def _copy_cell_style(src, dst):
    """å®‰å…¨å¤åˆ¶æ ·å¼ï¼šé¿å… StyleProxy å¯¼è‡´çš„ 'unhashable type: StyleProxy'"""
    try:
        if getattr(src, "has_style", False):
            dst.font = copy(src.font)
            dst.border = copy(src.border)
            dst.fill = copy(src.fill)
            dst.number_format = src.number_format
            dst.protection = copy(src.protection)
            dst.alignment = copy(src.alignment)
    except Exception:
        # æ ·å¼å¤åˆ¶å¤±è´¥ä¸å½±å“æ•°æ®/å…¬å¼è¾“å‡º
        pass



def write_match_sheet(wb, sku_cfg_df: pd.DataFrame):
    """
    æŠŠé…ç½®å†™å…¥æ¨¡æ¿çš„ã€ŒåŒ¹é…ã€sheetï¼Œåˆ—é¡ºåºå¿…é¡»æ˜¯ï¼š
      A SKU, B äº§å“åç§°, C é•¿, D å®½, E é«˜, F å•ç®±æ¯›é‡, G å•ç®±æ•°é‡(å¯æœ‰å¯æ— ï¼Œä½†ä¿ç•™)
    è¿™æ ·æ¨¡æ¿é‡Œçš„ï¼šVLOOKUP($E2,åŒ¹é…!$A:$F,3..6) æ‰èƒ½æ­£å¸¸å–åˆ°é•¿å®½é«˜/æ¯›é‡
    """
    if "åŒ¹é…" not in wb.sheetnames:
        wb.create_sheet("åŒ¹é…")
    ws = wb["åŒ¹é…"]

    ws.delete_rows(1, ws.max_row if ws.max_row > 0 else 1)

    headers = ["SKU", "äº§å“åç§°", "é•¿", "å®½", "é«˜", "å•ç®±æ¯›é‡", "å•ç®±æ•°é‡"]
    ws.append(headers)

    if sku_cfg_df is None or sku_cfg_df.empty:
        return

    for _, r in sku_cfg_df.iterrows():
        ws.append([
            str(r.get("SKU")).strip() if r.get("SKU") is not None else "",
            str(r.get("äº§å“åç§°")).strip() if r.get("äº§å“åç§°") is not None else "",
            None if pd.isna(r.get("é•¿")) else float(r.get("é•¿")),
            None if pd.isna(r.get("å®½")) else float(r.get("å®½")),
            None if pd.isna(r.get("é«˜")) else float(r.get("é«˜")),
            None if pd.isna(r.get("å•ç®±æ¯›é‡")) else float(r.get("å•ç®±æ¯›é‡")),
            None if pd.isna(r.get("å•ç®±æ•°é‡")) else float(r.get("å•ç®±æ•°é‡")),
        ])


def rebuild_main_sheet_with_data(
    ws,
    data_rows: List[Dict[str, Any]],
    pickup_date_cell: str,
    template_data_row: int = 2,
    template_total_row: int = 4,
):
    """
    ç”¨æ¨¡æ¿ç¬¬2è¡Œä½œä¸ºâ€œæ•°æ®è¡Œæ¨¡æ¿â€ï¼Œæ¨¡æ¿ç¬¬4è¡Œä½œä¸ºâ€œåˆè®¡è¡Œæ¨¡æ¿â€
    - å…‹éš†æ ·å¼+å…¬å¼åˆ° N è¡Œ
    - ç”¨è¡¨å¤´åŒ¹é…å†™å…¥éœ€è¦å†™å€¼çš„åˆ—ï¼ˆä¸è¦†ç›–å…¬å¼åˆ—ï¼‰
    """
    max_col = ws.max_column

    tmpl_cells = [ws.cell(template_data_row, c) for c in range(1, max_col + 1)]
    total_cells = [ws.cell(template_total_row, c) for c in range(1, max_col + 1)]

    tmpl_height = ws.row_dimensions[template_data_row].height
    total_height = ws.row_dimensions[template_total_row].height

    # åˆ é™¤æ—§æ•°æ®åŒºåŸŸ
    last = ws.max_row
    if last >= template_data_row:
        ws.delete_rows(template_data_row, last - template_data_row + 1)

    start_row = template_data_row
    n = len(data_rows)
    if n <= 0:
        return

    # æ’å…¥ n æ•°æ®è¡Œ + 1 åˆè®¡è¡Œ
    ws.insert_rows(start_row, amount=n + 1)

    headers = [ws.cell(1, c).value for c in range(1, max_col + 1)]
    col_map = {str(h).strip(): idx for idx, h in enumerate(headers, start=1) if h is not None}

    def setv(row_idx: int, col_name: str, val: Any):
        if col_name in col_map:
            ws.cell(row_idx, col_map[col_name]).value = val

    # å†™æ•°æ®è¡Œ
    for i, row_data in enumerate(data_rows):
        r = start_row + i

        # å…‹éš†æ¨¡æ¿è¡Œï¼ˆæ ·å¼+å…¬å¼ï¼‰
        for c in range(1, max_col + 1):
            src = tmpl_cells[c - 1]
            dst = ws.cell(r, c)
            _copy_cell_style(src, dst)

            if isinstance(src.value, str) and src.value.startswith("="):
                dst.value = Translator(src.value, origin=src.coordinate).translate_formula(dst.coordinate)
            else:
                # ä¸å†™æ­»å€¼ï¼Œåé¢ç”¨ setv å†™å…¥éœ€è¦å†™å€¼çš„åˆ—ï¼›å…¶ä½™ä¿æŒç©º/ç”±å…¬å¼åˆ—è´Ÿè´£
                dst.value = None

        if tmpl_height is not None:
            ws.row_dimensions[r].height = tmpl_height

        # å†™å€¼åˆ—ï¼ˆæŒ‰è¡¨å¤´åï¼‰
        setv(r, "é¢„è®¡æè´§æ—¥æœŸ", pickup_date_cell)
        setv(r, "é”€å”®è´Ÿè´£äºº", row_data.get("é”€å”®è´Ÿè´£äºº"))
        setv(r, "è´¦å·", row_data.get("è´¦å·"))
        setv(r, "FNSKU / UPC", row_data.get("FNSKU / UPC"))
        setv(r, "SKU", row_data.get("SKU"))
        setv(r, "äº§å“åç§°", row_data.get("äº§å“åç§°"))
        setv(r, "å‘è´§æ•°é‡", row_data.get("å‘è´§æ•°é‡"))
        setv(r, "å•ç®±æ•°é‡", row_data.get("å•ç®±æ•°é‡"))
        setv(r, "ç‰©æµæ¸ é“", row_data.get("ç‰©æµæ¸ é“"))
        setv(r, "å‘è´§ä»“åº“", row_data.get("å‘è´§ä»“åº“"))
        setv(r, "FBA ID", row_data.get("FBA ID"))
        setv(r, "Reference ID", row_data.get("Reference ID"))
        setv(r, "åˆ°è´§ä»“åº“", row_data.get("åˆ°è´§ä»“åº“"))
        setv(r, "ä»“åº“ä»£ç ", row_data.get("ä»“åº“ä»£ç "))
        setv(r, "å·¥å‚åœ°å€", row_data.get("å·¥å‚åœ°å€"))

    # åˆè®¡è¡Œ
    total_row = start_row + n
    for c in range(1, max_col + 1):
        src = total_cells[c - 1]
        dst = ws.cell(total_row, c)
        _copy_cell_style(src, dst)
        dst.value = None

    if total_height is not None:
        ws.row_dimensions[total_row].height = total_height

    # é‡æ–°å†™åˆè®¡åˆ—ï¼ˆå¦‚æœæ¨¡æ¿å°±æ˜¯ SUM ä¹Ÿè¡Œï¼Œè¿™é‡Œå¼ºåˆ¶æŒ‰å®é™…èŒƒå›´ï¼‰
    def set_sum(col_letter: str):
        col_idx = openpyxl.utils.column_index_from_string(col_letter)
        ws.cell(total_row, col_idx).value = f"=SUM({col_letter}{start_row}:{col_letter}{start_row + n - 1})"

    for col_letter in ["G", "J", "V", "W", "X"]:
        try:
            set_sum(col_letter)
        except Exception:
            pass

    ws.freeze_panes = "A2"
    ws.auto_filter.ref = ws.dimensions


# ========= ä¸»æµç¨‹ =========
def build_data_rows_from_file1(
    df: pd.DataFrame,
    sku_cfg_df: pd.DataFrame,
    sku_factory_short: Dict[str, str],
    factory_name_to_addr: Dict[str, str],
    supplier_value: Any,
) -> List[Dict[str, Any]]:
    """
    æŠŠæ–‡ä»¶1çš„è¡Œæ˜ å°„ä¸ºæ¨¡æ¿éœ€è¦çš„â€œå€¼åˆ—â€
    - é”€å”®è´Ÿè´£äººï¼šæ¥è‡ªæ–‡ä»¶1åˆ—â€œè¿è¥â€
    - å·¥å‚åœ°å€ï¼šä¼˜å…ˆç”¨ SKU->å·¥å‚ç®€ç§° -> å·¥å‚ä¿¡æ¯æ¨¡ç³ŠåŒ¹é…ï¼›å†ç”¨ä¾›åº”å•†åæ¨¡ç³ŠåŒ¹é…
    - å•ç®±æ•°é‡ï¼šä¼˜å…ˆæ–‡ä»¶1çš„â€œç®±è§„â€ï¼Œå¦åˆ™ç”¨é…ç½®è¡¨ sku_cfg_df çš„å•ç®±æ•°é‡
    """
    op_col = find_col(df.columns, ["è¿è¥"])
    acct_col = find_col(df.columns, ["åº—é“ºè´¦å·/ç›®çš„ä»“åº“", "è´¦å·"])
    fns_col = find_col(df.columns, ["FNSKU / UPC", "FNSKU/UPC", "FNSKU"])
    sku_col = find_col(df.columns, ["ä»“åº“SKU", "SKU"])
    prod_col = find_col(df.columns, ["äº§å“åç§°", "å“å"])
    qty_col = find_col(df.columns, ["å‘è´§æ•°é‡", "æ•°é‡"])
    carton_col = choose_best_numeric_col(df, "ç®±è§„")
    ship_mode_col = find_col(df.columns, ["ç‰©æµæ¸ é“", "ç‰©æµæ–¹å¼"])
    ship_from_col = find_col(df.columns, ["å‘è´§ä»“åº“", "å‘è´§ä»“"])
    fba_col = find_col_exact(df.columns, ["FBAè´§ä»¶ç¼–å·", "FBA ID", "FBAè´§ä»¶ID", "FBAè´§ä»¶å·"])
    ref_col = find_col_exact(df.columns, ["TFè°ƒæ‹¨å•", "TFè°ƒæ‹¨å•å·", "è°ƒæ‹¨å•å·", "TFå•å·", "è°ƒæ‹¨å•", "Reference ID", "å‚è€ƒå•å·"])
    dest_col = find_col(df.columns, ["é…é€åœ°å€/æ”¶è´§äººä¿¡æ¯", "åˆ°è´§ä»“åº“"])
    wh_code_col = find_col(df.columns, ["ä»“åº“ä»£ç "])

    cfg_carton_map = {}
    if sku_cfg_df is not None and not sku_cfg_df.empty:
        # SKU -> å•ç®±æ•°é‡
        tmp = sku_cfg_df[["SKU", "å•ç®±æ•°é‡"]].copy()
        tmp["SKU"] = tmp["SKU"].astype(str)
        cfg_carton_map = dict(zip(tmp["SKU"], tmp["å•ç®±æ•°é‡"]))

    supplier_full = str(supplier_value).strip() if supplier_value is not None else ""
    supplier_short = supplier_short_name(supplier_full)

    rows: List[Dict[str, Any]] = []
    for _, r in df.iterrows():
        sku = str(r.get(sku_col)).strip() if sku_col and r.get(sku_col) is not None else ""
        fac_short = sku_factory_short.get(sku, "")
        addr = fuzzy_factory_address([fac_short, supplier_short, supplier_full], factory_name_to_addr)

        # å•ç®±æ•°é‡ï¼ˆç®±è§„ï¼‰
        carton = None
        if carton_col:
            carton = pd.to_numeric(r.get(carton_col), errors="coerce")
            carton = None if pd.isna(carton) else float(carton)
        if carton is None and sku in cfg_carton_map:
            v = cfg_carton_map.get(sku)
            if v is not None and not (isinstance(v, float) and np.isnan(v)):
                carton = float(v)

        rows.append({
            "é”€å”®è´Ÿè´£äºº": r.get(op_col) if op_col else None,
            "è´¦å·": r.get(acct_col) if acct_col else None,
            "FNSKU / UPC": r.get(fns_col) if fns_col else None,
            "SKU": sku if sku else None,
            "äº§å“åç§°": r.get(prod_col) if prod_col else None,
            "å‘è´§æ•°é‡": r.get(qty_col) if qty_col else None,
            "å•ç®±æ•°é‡": carton,
            "ç‰©æµæ¸ é“": r.get(ship_mode_col) if ship_mode_col else None,
            "å‘è´§ä»“åº“": r.get(ship_from_col) if ship_from_col else None,
            "FBA ID": (norm_id_value(r.get(ref_col)) if ref_col else ""),
            "Reference ID": (norm_id_value(r.get(fba_col)) if fba_col else ""),
            "åˆ°è´§ä»“åº“": r.get(dest_col) if dest_col else None,
            "ä»“åº“ä»£ç ": r.get(wh_code_col) if wh_code_col else None,
            "å·¥å‚åœ°å€": addr,
        })
    return rows



def choose_shipment_folder_id(df: pd.DataFrame, fba_col: Optional[str], ref_col: Optional[str]) -> str:
    """
    æ‹†åˆ†åè¾“å‡ºæ–‡ä»¶ç»Ÿä¸€æ”¾åˆ°â€œFBA IDâ€æ–‡ä»¶å¤¹é€»è¾‘ï¼š
    - ä¼˜å…ˆç”¨ FBAè´§ä»¶ç¼–å·/FBA IDï¼ˆå³ä½¿æ˜¯ä¸­ä»“ä¹Ÿä¸€æ ·ï¼‰
    - å¦‚æœæ²¡æœ‰FBAï¼Œåˆ™ä½¿ç”¨TFè°ƒæ‹¨å•/è°ƒæ‹¨å•å·ï¼ˆä»ç„¶å½’å…¥åŒä¸€å±‚IDæ–‡ä»¶å¤¹ï¼Œä¸å†å•ç‹¬å»ºTFç›®å½•ï¼‰
    """
    def _pick_first(colname: Optional[str]) -> str:
        if not colname or colname not in df.columns:
            return ""
        for v in df[colname].fillna("").astype(str).tolist():
            s = v.strip()
            if s:
                return s
        return ""

    sid = _pick_first(fba_col)
    if not sid:
        sid = _pick_first(ref_col)

    sid = (sid or "UNKNOWN").strip()
    # folder name safe
    sid = sanitize_filename(sid.upper())
    return sid


def resolve_template_path(template_input: str) -> str:
    t = (template_input or "").strip()
    if t and os.path.isfile(t):
        return t

    # å¦‚æœç”¨æˆ·æ²¡é€‰æ¨¡æ¿ï¼Œå°±å°è¯•è„šæœ¬/EXEåŒç›®å½•çš„é»˜è®¤æ¨¡æ¿å
    base_dir = os.path.dirname(os.path.abspath(__file__))
    candidate = os.path.join(base_dir, DEFAULT_TEMPLATE_NAME)
    if os.path.isfile(candidate):
        return candidate

    raise ValueError("æ‰¾ä¸åˆ°æ¨¡æ¿æ–‡ä»¶ã€‚è¯·åœ¨UIé‡Œé€‰æ‹©â€œæ–‡ä»¶2æ¨¡æ¿ï¼ˆå«å…¬å¼ï¼‰â€ï¼Œæˆ–æŠŠæ¨¡æ¿æ”¾åˆ°ç¨‹åºåŒç›®å½•å¹¶å‘½åä¸ºï¼šå·¥å‚æè´§æ˜ç»†æ¨¡æ¿.xlsx")


def process_file(
    file1: str,
    template_path_input: str,
    cfg_path: str,
    out_root: str,
    pickup_date: str,
    time_tag: str,
    product_tag: str,
    filename_name: str,
    split_supplier_folder: bool,
    progress_cb: Optional[Callable[[int, int, str], None]] = None,
    log_cb: Optional[Callable[[str], None]] = None,
) -> List[str]:
    pickup_cell, pickup_fname = parse_date(pickup_date)

    # è¾“å‡ºï¼šè‡ªåŠ¨åˆ›å»º ç›´å‘MMDD æ–‡ä»¶å¤¹
    out_base = os.path.join(out_root, f"ç›´å‘{pickup_fname[5:7]}{pickup_fname[8:10]}")
    os.makedirs(out_base, exist_ok=True)

    # è¯»æ–‡ä»¶1
    sheet, header_row = detect_sheet_and_header_row(file1)
    df1 = pd.read_excel(file1, sheet_name=sheet, header=header_row - 1, engine="openpyxl")
    df1.columns = [str(c).strip() if c is not None else "" for c in df1.columns]

    direct_col = find_col(df1.columns, ["ä¸­ä»“ æˆ– å·¥å‚ç›´å‘", "ä¸­ä»“æˆ–å·¥å‚ç›´å‘", "å·¥å‚ç›´å‘"])
    supplier_col = find_col(df1.columns, ["ä¾›åº”å•†", "ä¾›åº”å•†åç§°", "å·¥å‚"])
    if direct_col is None or supplier_col is None:
        raise ValueError(f"æ‰¾ä¸åˆ°å¿…è¦åˆ—ï¼š{direct_col=} , {supplier_col=}ã€‚è¯·ç¡®è®¤æ–‡ä»¶1è¡¨å¤´æ˜¯å¦ä¸€è‡´ã€‚")

    ser = df1[direct_col].astype(str).str.replace(" ", "").str.replace("\u3000", "")
    df_f = df1[ser.str.contains("å·¥å‚ç›´å‘", na=False)].copy()
    if df_f.empty:
        return []

    # éâ€œå·¥å‚ç›´å‘â€çš„è¡Œï¼ˆä¾‹å¦‚ï¼šä¸­ä»“ï¼‰â€”â€”ç”¨äºç”Ÿæˆä¸€ä¸ªæ±‡æ€»æ€»è¡¨
    df_non = df1[~ser.str.contains("å·¥å‚ç›´å‘", na=False)].copy()

    # ä»…ä¿ç•™ Amazonï¼ˆä¸­ä»“æ±‡æ€»åªè¦äºšé©¬é€Šï¼Œè¿‡æ»¤æ‰ Shopify/Walmart ç­‰ï¼‰
    try:
        ch_col = find_col(df_non.columns, ["æ¸ é“", "å¹³å°", "å¹³å°ç«™ç‚¹", "ç«™ç‚¹", "Channel", "Platform", "åº—é“º", "è´¦å·", "è´¦æˆ·"])
        if ch_col is not None:
            _ser = df_non[ch_col].astype(str).str.lower()
            df_non = df_non[_ser.str.contains("amazon|äºšé©¬é€Š|amz", na=False)].copy()
    except Exception:
        pass


    # è¯»é…ç½®
    sku_cfg_df, sku_factory_short, factory_name_to_addr = load_config_xlsx(cfg_path)
    sku_cfg_df = merge_missing_skus_from_file1(sku_cfg_df, df_f)

    # æ¨¡æ¿è·¯å¾„
    template_path = resolve_template_path(template_path_input)

    outputs = []
    # ç»Ÿä¸€å½’æ¡£IDï¼šä¼˜å…ˆ FBAè´§ä»¶ç¼–å·/FBA IDï¼›è‹¥æ— åˆ™ç”¨ TFè°ƒæ‹¨å•/è°ƒæ‹¨å•å·
    fba_col = find_col_exact(df_f.columns, ["FBAè´§ä»¶ç¼–å·", "FBA ID", "FBAè´§ä»¶ID", "FBAè´§ä»¶å·"])
    ref_col = find_col_exact(df_f.columns, ["TFè°ƒæ‹¨å•", "TFè°ƒæ‹¨å•å·", "è°ƒæ‹¨å•å·", "TFå•å·", "è°ƒæ‹¨å•", "Reference ID", "å‚è€ƒå•å·"])

    groups = list(df_f.groupby(supplier_col))
    total = len(groups)

    # å…ˆé¢„è®¡ç®—ï¼šæ¯ä¸ªä¾›åº”å•†å¯¹åº”çš„â€œæ ‡å‡†å·¥å‚æ–‡ä»¶å¤¹åâ€
    supplier_to_factory: Dict[str, str] = {}
    factory_to_suppliers: Dict[str, set] = {}
    for supplier, _g in groups:
        sup_short = supplier_short_name(supplier)
        factory_folder = fuzzy_factory_name([sup_short, str(supplier)], factory_name_to_addr) or sup_short
        supplier_to_factory[str(supplier)] = factory_folder
        factory_to_suppliers.setdefault(factory_folder, set()).add(sup_short)

    for i, (supplier, g) in enumerate(groups, start=1):
        sup_short = supplier_short_name(supplier)

        # å·¥å‚æ–‡ä»¶å¤¹åï¼šä½¿ç”¨é¢„è®¡ç®—ç»“æœï¼ˆé…ç½®è¡¨åŒ¹é…ä¼˜å…ˆï¼‰
        factory_folder = supplier_to_factory.get(str(supplier), sup_short)

        # è¾“å‡ºç›®å½•ï¼š
        # - åªæ‹†åˆ†åˆ°â€œå·¥å‚â€ï¼ˆä¸å†åˆ›å»º FBA/TF çš„å­æ–‡ä»¶å¤¹ï¼‰
        # - ä¸å‹¾ï¼šè¾“å‡º/ç›´å‘MMDD/...ï¼ˆå…¨éƒ¨æ–‡ä»¶ç›´æ¥æ”¾åœ¨ç›´å‘MMDDæ ¹ç›®å½•ï¼‰
        # - å‹¾ä¸Šï¼šè¾“å‡º/ç›´å‘MMDD/å·¥å‚(é…ç½®å)/...ï¼ˆåªåˆ°å·¥å‚è¿™ä¸€å±‚ï¼Œä¸å†åˆ›å»ºä¾›åº”å•†ç¬¬ä¸‰çº§ï¼‰
        if split_supplier_folder:
            folder = os.path.join(out_base, factory_folder)
        else:
            folder = out_base


        os.makedirs(folder, exist_ok=True)

        # æ•°æ®è¡Œæ˜ å°„
        data_rows = build_data_rows_from_file1(
            df=g,
            sku_cfg_df=sku_cfg_df,
            sku_factory_short=sku_factory_short,
            factory_name_to_addr=factory_name_to_addr,
            supplier_value=supplier,
        )

        # æ‰“å¼€æ¨¡æ¿ + å†™åŒ¹é…sheet + å†™ä¸»è¡¨
        wb = openpyxl.load_workbook(template_path)
                # ä»…ä¿ç•™æœ¬æ¬¡æ‹†åˆ†æ¶‰åŠçš„ SKUï¼ˆå‡å°‘åŒ¹é…è¡¨å†—ä½™ï¼‰
        try:
            sku_in_file = {str(rr.get('SKU')).strip() for rr in data_rows if rr.get('SKU') is not None}
            sku_in_file = {s for s in sku_in_file if s}
            sku_cfg_sub = sku_cfg_df[sku_cfg_df['SKU'].astype(str).str.strip().isin(sku_in_file)].copy() if (sku_cfg_df is not None and not sku_cfg_df.empty and sku_in_file) else sku_cfg_df
        except Exception:
            sku_cfg_sub = sku_cfg_df
        write_match_sheet(wb, sku_cfg_sub)

        if "å·¥å‚æè´§æ˜ç»†" not in wb.sheetnames:
            raise ValueError("æ¨¡æ¿æ–‡ä»¶ç¼ºå°‘ sheetï¼šå·¥å‚æè´§æ˜ç»†")
        ws = wb["å·¥å‚æè´§æ˜ç»†"]

        rebuild_main_sheet_with_data(
            ws=ws,
            data_rows=data_rows,
            pickup_date_cell=pickup_cell,
            template_data_row=2,
            template_total_row=4,
        )

        # ä¿å­˜
        # æ–‡ä»¶åï¼šå§“å-ã€æ—¥æœŸ+æ—¶é—´(å¯é€‰) + äº§å“(å¯é€‰)+ä¾›åº”å•†ã€‘å·¥å‚æè´§æ˜ç»†è¡¨
        tag = pickup_fname
        t = sanitize_filename(time_tag) if time_tag else ""
        p = sanitize_filename(product_tag) if product_tag else ""
        if t:
            tag += f"+{t}"
        if p:
            sep = " + " if t else "+"  # åªæœ‰æ—¶é—´å­˜åœ¨æ—¶ï¼Œç”¨ â€œ + â€ åˆ†éš”äº§å“ï¼Œç¬¦åˆä½ ç¤ºä¾‹
            tag += f"{sep}{p}"
        tag += f"+{sup_short}"
        filename = f"{sanitize_filename(filename_name)}-ã€{tag}ã€‘å·¥å‚æè´§æ˜ç»†è¡¨.xlsx"
        out_path = os.path.join(folder, filename)

        base, ext = os.path.splitext(out_path)
        k = 1
        while os.path.exists(out_path):
            out_path = f"{base}({k}){ext}"
            k += 1

        wb.save(out_path)
        outputs.append(out_path)

        if log_cb:
            log_cb(f"âœ… {sup_short} -> {out_path}")

        if progress_cb:
            progress_cb(i, total, sup_short)
    # ç”Ÿæˆâ€œä¸­ä»“ç›´å‘YYYYMMDDâ€æ±‡æ€»è¡¨ï¼ˆæ”¾åœ¨ out_base ç›®å½•ï¼‰
    if df_non is not None and not df_non.empty:
        try:
            # æ•°æ®è¡Œï¼šæŒ‰ä¾›åº”å•†åˆ†ç»„ç”Ÿæˆï¼ˆç¡®ä¿å·¥å‚åœ°å€æ¨¡ç³ŠåŒ¹é…æŒ‰ä¾›åº”å•†ç”Ÿæ•ˆï¼‰
            data_rows_non = []
            if supplier_col is not None:
                for sup, gg in df_non.groupby(supplier_col):
                    data_rows_non.extend(build_data_rows_from_file1(
                        df=gg,
                        sku_cfg_df=sku_cfg_df,
                        sku_factory_short=sku_factory_short,
                        factory_name_to_addr=factory_name_to_addr,
                        supplier_value=sup,
                    ))
            else:
                data_rows_non = build_data_rows_from_file1(
                    df=df_non,
                    sku_cfg_df=sku_cfg_df,
                    sku_factory_short=sku_factory_short,
                    factory_name_to_addr=factory_name_to_addr,
                    supplier_value="",
                )
            # ä¸­ä»“/éå·¥å‚ç›´å‘ï¼šä¿æŒåŸå§‹æ ¼å¼è¾“å‡ºï¼ˆä¸å¥—æ¨¡æ¿ï¼‰
            

            yyyymmdd = pickup_fname.replace(".", "")
            sum_name = f"ä¸­ä»“{yyyymmdd}.xlsx"
            sum_path = os.path.join(out_base, sum_name)

            base, ext = os.path.splitext(sum_path)
            k = 1
            while os.path.exists(sum_path):
                sum_path = f"{base}({k}){ext}"
                k += 1

            export_mid_warehouse_keep_format(file1, sheet, header_row, sum_path, log_cb=log_cb)

            if log_cb:
                log_cb(f"ğŸ“Œ æ±‡æ€»è¡¨ -> {sum_path}")
        except Exception as _ex:
            # æ±‡æ€»è¡¨å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
            if log_cb:
                log_cb(f"âš ï¸ æ±‡æ€»è¡¨ç”Ÿæˆå¤±è´¥ï¼š{_ex}")


    return outputs


# ========= UI =========
class App(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("å·¥å‚æè´§æ˜ç»†è¡¨è‡ªåŠ¨æ‹†åˆ†ï¼ˆä¿ç•™æ¨¡æ¿å…¬å¼ + SKU/å·¥å‚é…ç½®ï¼‰")
        self.geometry("980x640")
        self.resizable(True, True)

        self.file1_var = tk.StringVar()
        self.template_var = tk.StringVar()   # å¯é€‰ï¼šä¸å¡«åˆ™æ‰¾åŒç›®å½•é»˜è®¤æ¨¡æ¿
        self.cfg_var = tk.StringVar()
        self.outdir_var = tk.StringVar()
        self.date_var = tk.StringVar()
        self.time_var = tk.StringVar()
        self.product_var = tk.StringVar()
        self.name_var = tk.StringVar()
        self.split_var = tk.BooleanVar(value=True)
        # --- ç§¯åŠ è®¤è¯ï¼ˆç”¨äºä¸‹è½½ FBA ç®±å”›ï¼‰---
        self.token_var = tk.StringVar()
        self.acc_var = tk.StringVar()
        self.pwd_var = tk.StringVar()
        self.enable_fba_label_var = tk.BooleanVar(value=True)
        self.fba_cooldown_var = tk.StringVar(value=str(FBA_PRINT_COOLDOWN_DEFAULT_SEC))

        self._build_ui()
        self._load_config()
        self.protocol("WM_DELETE_WINDOW", self._on_close)

    def _build_ui(self):
        frm = ttk.Frame(self, padding=12)
        frm.pack(fill="both", expand=True)
        frm.columnconfigure(1, weight=1)
        frm.rowconfigure(12, weight=1)

        r = 0
        ttk.Label(frm, text="æ–‡ä»¶1ï¼ˆçº¿ä¸Šå–å›æ•°æ®ï¼‰").grid(row=r, column=0, sticky="w")
        ttk.Entry(frm, textvariable=self.file1_var).grid(row=r, column=1, sticky="we", padx=8)
        ttk.Button(frm, text="æµè§ˆâ€¦", command=self._pick_file1).grid(row=r, column=2, sticky="e")

        r += 1
        ttk.Label(frm, text=f"æ–‡ä»¶2æ¨¡æ¿ï¼ˆå«å…¬å¼ï¼Œå¯é€‰ï¼›ä¸é€‰åˆ™è‡ªåŠ¨æ‰¾åŒç›®å½•ï¼š{DEFAULT_TEMPLATE_NAME}ï¼‰").grid(row=r, column=0, sticky="w", pady=(8, 0))
        ttk.Entry(frm, textvariable=self.template_var).grid(row=r, column=1, sticky="we", padx=8, pady=(8, 0))
        ttk.Button(frm, text="é€‰æ‹©â€¦", command=self._pick_template).grid(row=r, column=2, sticky="e", pady=(8, 0))

        r += 1
        ttk.Label(frm, text="é…ç½®æ–‡ä»¶ï¼ˆä½ ç»™çš„SKUä¿¡æ¯/å·¥å‚ä¿¡æ¯ï¼‰").grid(row=r, column=0, sticky="w", pady=(8, 0))
        ttk.Entry(frm, textvariable=self.cfg_var).grid(row=r, column=1, sticky="we", padx=8, pady=(8, 0))
        ttk.Button(frm, text="é€‰æ‹©â€¦", command=self._pick_cfg).grid(row=r, column=2, sticky="e", pady=(8, 0))

        r += 1
        ttk.Label(frm, text="è¾“å‡ºæ ¹ç›®å½•ï¼ˆç¨‹åºä¼šè‡ªåŠ¨åœ¨é‡Œé¢å»ºï¼šç›´å‘MMDDï¼Œä¾‹å¦‚ ç›´å‘1225ï¼‰").grid(row=r, column=0, sticky="w", pady=(8, 0))
        ttk.Entry(frm, textvariable=self.outdir_var).grid(row=r, column=1, sticky="we", padx=8, pady=(8, 0))
        ttk.Button(frm, text="é€‰æ‹©â€¦", command=self._pick_outdir).grid(row=r, column=2, sticky="e", pady=(8, 0))

        r += 1
        sub = ttk.Frame(frm)
        sub.grid(row=r, column=0, columnspan=3, sticky="we", pady=(10, 0))
        # è®©ä¸­é—´è¾“å…¥æ¡†å¯æ‰©å±•
        sub.columnconfigure(1, weight=0)
        sub.columnconfigure(3, weight=0)
        sub.columnconfigure(5, weight=0)
        sub.columnconfigure(7, weight=1)

        ttk.Label(sub, text="é¢„è®¡æè´§æ—¥æœŸ").grid(row=0, column=0, sticky="w")
        ttk.Entry(sub, textvariable=self.date_var, width=14).grid(row=0, column=1, sticky="w", padx=(8, 16))

        ttk.Label(sub, text="æ—¶é—´ï¼ˆé€‰å¡«ï¼Œå¦‚ï¼š13ç‚¹ï¼‰").grid(row=0, column=2, sticky="w")
        ttk.Entry(sub, textvariable=self.time_var, width=10).grid(row=0, column=3, sticky="w", padx=(8, 16))

        ttk.Label(sub, text="äº§å“ï¼ˆé€‰å¡«ï¼Œå¦‚ï¼šç©ºæ»¤ï¼‰").grid(row=0, column=4, sticky="w")
        ttk.Entry(sub, textvariable=self.product_var, width=12).grid(row=0, column=5, sticky="w", padx=(8, 16))

        ttk.Label(sub, text="å§“å").grid(row=0, column=6, sticky="w")
        ttk.Entry(sub, textvariable=self.name_var, width=12).grid(row=0, column=7, sticky="w", padx=(8, 0))

        r += 1
        opt = ttk.Frame(frm)
        opt.grid(row=r, column=0, columnspan=3, sticky="we", pady=(10, 0))
        ttk.Checkbutton(opt, text="æŒ‰ä¾›åº”å•†å»ºç«‹äºŒçº§æ–‡ä»¶å¤¹ï¼ˆå‹¾ä¸Šï¼šè¾“å‡º/ç›´å‘MMDD/ä¾›åº”å•†/â€¦ï¼›ä¸å‹¾ï¼šè¾“å‡º/ç›´å‘MMDD/â€¦ï¼‰", variable=self.split_var).pack(side="left")
        # --- FBA ç®±å”›ä¸‹è½½ï¼ˆå¢é‡åŒºåŸŸï¼Œä¸å½±å“æ‹†åˆ†é€»è¾‘ï¼‰ ---
        r += 1
        auth = ttk.LabelFrame(frm, text="FBAç®±å”›ä¸‹è½½ï¼ˆå¯é€‰ï¼‰", padding=10)
        auth.grid(row=r, column=0, columnspan=3, sticky="we", pady=(12, 0))
        auth.columnconfigure(1, weight=1)
        auth.columnconfigure(3, weight=0)
        auth.columnconfigure(4, weight=0)

        ttk.Checkbutton(auth, text="æ‹†åˆ†å®Œæˆåè‡ªåŠ¨ä¸‹è½½ FBA ç®±å”›ï¼ˆæŸ¥è¯¢â†’æ‰“å°â†’ä¸‹è½½ZIPï¼‰", variable=self.enable_fba_label_var).grid(row=0, column=0, columnspan=4, sticky="w")

        ttk.Label(auth, text="x-auth-token").grid(row=1, column=0, sticky="w", pady=(8, 0))
        ttk.Entry(auth, textvariable=self.token_var).grid(row=1, column=1, columnspan=3, sticky="we", padx=8, pady=(8, 0))

        ttk.Label(auth, text="cookieï¼ˆè‡³å°‘åŒ…å« sensorsdata...ï¼‰").grid(row=2, column=0, sticky="nw", pady=(8, 0))
        cookie_entry = tk.Text(auth, height=3)
        cookie_entry.grid(row=2, column=1, columnspan=3, sticky="we", padx=8, pady=(8, 0))
        self._cookie_text = cookie_entry

        ttk.Label(auth, text="è´¦å·").grid(row=3, column=0, sticky="w", pady=(8, 0))
        ttk.Entry(auth, textvariable=self.acc_var, width=24).grid(row=3, column=1, sticky="w", padx=8, pady=(8, 0))

        ttk.Label(auth, text="å¯†ç ").grid(row=3, column=2, sticky="w", pady=(8, 0))
        ttk.Entry(auth, textvariable=self.pwd_var, width=24, show="*").grid(row=3, column=3, sticky="w", padx=8, pady=(8, 0))

        ttk.Label(auth, text="æ‰“å°é—´éš”(ç§’)").grid(row=4, column=0, sticky="w", pady=(8, 0))
        ttk.Entry(auth, textvariable=self.fba_cooldown_var, width=8).grid(row=4, column=1, sticky="w", padx=8, pady=(8, 0))
        ttk.Label(auth, text="ï¼ˆé»˜è®¤35ï¼›ä¸¤æ¬¡æ‰¹é‡æ‰“å°ä¹‹é—´ç­‰å¾…ï¼‰").grid(row=4, column=2, columnspan=2, sticky="w", pady=(8, 0))

        ttk.Button(auth, text="è‡ªåŠ¨ç™»å½•è·å–token/cookieï¼ˆå¯é€‰ï¼‰", command=self._auto_login).grid(row=1, column=4, rowspan=2, sticky="ns", padx=10, pady=(8, 0))

        r += 1
        btns = ttk.Frame(frm)
        btns.grid(row=r, column=0, columnspan=3, sticky="we", pady=(12, 0))
        self.run_btn = ttk.Button(btns, text="å¼€å§‹æ‹†åˆ†", command=self._start)
        self.run_btn.pack(side="left")
        ttk.Button(btns, text="æ‰“å¼€è¾“å‡ºç›®å½•", command=self._open_outdir).pack(side="left", padx=10)

        r += 1
        prog = ttk.Frame(frm)
        prog.grid(row=r, column=0, columnspan=3, sticky="we", pady=(12, 0))
        prog.columnconfigure(0, weight=1)

        self.progress = ttk.Progressbar(prog, mode="determinate")
        self.progress.grid(row=0, column=0, sticky="we")
        self.progress_label = ttk.Label(prog, text="0%")
        self.progress_label.grid(row=0, column=1, sticky="e", padx=(8, 0))

        r += 1
        ttk.Label(frm, text="æ—¥å¿—").grid(row=r, column=0, sticky="w", pady=(12, 0))
        r += 1
        self.log = ScrolledText(frm, height=18)
        self.log.grid(row=r, column=0, columnspan=3, sticky="nsew", pady=(6, 0))

    
    def _auto_login(self):
        try:
            acc = self.acc_var.get().strip()
            pwd = self.pwd_var.get().strip()
            if not acc or not pwd:
                messagebox.showinfo("æç¤º", "è¯·å…ˆè¾“å…¥è´¦å·å’Œå¯†ç ã€‚")
                return
            self._append_log("ğŸŒ å¼€å§‹è‡ªåŠ¨ç™»å½•è·å– token/cookie ...")
            token, cookie = auto_login_get_token_cookie(acc, pwd, log_cb=self._append_log)
            if token:
                self.token_var.set(token)
            if hasattr(self, "_cookie_text"):
                self._cookie_text.delete("1.0", "end")
                self._cookie_text.insert("1.0", cookie)
            self._append_log("âœ… å·²è·å– cookieï¼ˆtoken è‹¥ä¸ºç©ºå¯æ‰‹åŠ¨ç²˜è´´ x-auth-tokenï¼‰ã€‚")
            self._save_config()
        except Exception as ex:
            self._append_log(f"âŒ è‡ªåŠ¨ç™»å½•å¤±è´¥ï¼š{ex}")
            messagebox.showerror("è‡ªåŠ¨ç™»å½•å¤±è´¥", str(ex))

    def _pick_file1(self):
        p = filedialog.askopenfilename(title="é€‰æ‹©æ–‡ä»¶1", filetypes=[("Excel", "*.xlsx;*.xls"), ("All", "*.*")])
        if p:
            self.file1_var.set(p)

    def _pick_template(self):
        p = filedialog.askopenfilename(title="é€‰æ‹©æ¨¡æ¿æ–‡ä»¶ï¼ˆå«å…¬å¼ï¼‰", filetypes=[("Excel", "*.xlsx;*.xls"), ("All", "*.*")])
        if p:
            self.template_var.set(p)

    def _pick_cfg(self):
        p = filedialog.askopenfilename(title="é€‰æ‹©é…ç½®æ–‡ä»¶", filetypes=[("Excel", "*.xlsx;*.xls"), ("All", "*.*")])
        if p:
            self.cfg_var.set(p)

    def _pick_outdir(self):
        p = filedialog.askdirectory(title="é€‰æ‹©è¾“å‡ºæ ¹ç›®å½•")
        if p:
            self.outdir_var.set(p)

    def _open_outdir(self):
        p = self.outdir_var.get().strip()
        if not p:
            messagebox.showinfo("æç¤º", "è¯·å…ˆé€‰æ‹©è¾“å‡ºæ ¹ç›®å½•ã€‚")
            return
        if not os.path.isdir(p):
            messagebox.showerror("é”™è¯¯", "è¾“å‡ºæ ¹ç›®å½•ä¸å­˜åœ¨ã€‚")
            return
        try:
            os.startfile(p)
        except Exception:
            messagebox.showinfo("æç¤º", f"è¾“å‡ºç›®å½•ï¼š{p}")

    def _append_log(self, msg: str):
        self.log.insert("end", msg + "\n")
        self.log.see("end")

    def _set_progress(self, done: int, total: int, supplier_short: str):
        pct = int(done * 100 / max(total, 1))
        self.progress["maximum"] = total
        self.progress["value"] = done
        self.progress_label.config(text=f"{pct}%  ({done}/{total})  {supplier_short}")

    def _validate_inputs(self) -> Tuple[str, str, str, str, str, str, str, str, bool]:
        file1 = self.file1_var.get().strip()
        template = self.template_var.get().strip()  # optional
        cfg = self.cfg_var.get().strip()
        outdir = self.outdir_var.get().strip()
        date_str = self.date_var.get().strip()
        time_tag = self.time_var.get().strip()
        product_tag = self.product_var.get().strip()
        name = self.name_var.get().strip()
        split_supplier = bool(self.split_var.get())

        if not file1 or not os.path.isfile(file1):
            raise ValueError("è¯·é€‰æ‹©æ­£ç¡®çš„æ–‡ä»¶1è·¯å¾„ã€‚")
        if not cfg or not os.path.isfile(cfg):
            raise ValueError("è¯·é€‰æ‹©æ­£ç¡®çš„é…ç½®æ–‡ä»¶è·¯å¾„ã€‚")
        if not outdir:
            raise ValueError("è¯·é€‰æ‹©è¾“å‡ºæ ¹ç›®å½•ã€‚")
        os.makedirs(outdir, exist_ok=True)
        if not date_str:
            raise ValueError("è¯·è¾“å…¥é¢„è®¡æè´§æ—¥æœŸã€‚")
        if not name:
            raise ValueError("è¯·è¾“å…¥å§“åï¼ˆç”¨äºæ–‡ä»¶åå‰ç¼€ï¼‰ã€‚")

        # æ ¡éªŒæ—¥æœŸ
        parse_date(date_str)

        # æ ¡éªŒæ¨¡æ¿ï¼šå…è®¸ä¸ºç©ºï¼ˆè‡ªåŠ¨æ‰¾åŒç›®å½•é»˜è®¤æ¨¡æ¿ï¼‰
        _ = resolve_template_path(template)

        return file1, template, cfg, outdir, date_str, time_tag, product_tag, name, split_supplier

    def _start(self):
        try:
            file1, template, cfg, outdir, date_str, time_tag, product_tag, name, split_supplier = self._validate_inputs()
        except Exception as e:
            messagebox.showerror("è¾“å…¥æœ‰è¯¯", str(e))
            return

        self.run_btn.config(state="disabled")
        self.progress["value"] = 0
        self.progress_label.config(text="0%")
        self.log.delete("1.0", "end")
        self._append_log("å¼€å§‹å¤„ç†â€¦")

        self._save_config()

        def progress_cb(done, total, supplier_short):
            self.after(0, lambda: self._set_progress(done, total, supplier_short))

        def log_cb(msg):
            self.after(0, lambda: self._append_log(msg))

        def worker():
            try:
                outs = process_file(
                    file1=file1,
                    template_path_input=template,
                    cfg_path=cfg,
                    out_root=outdir,
                    pickup_date=date_str,
                    time_tag=time_tag,
                    product_tag=product_tag,
                    filename_name=name,
                    split_supplier_folder=split_supplier,
                    progress_cb=progress_cb,
                    log_cb=log_cb,
                )
                if not outs:
                    self.after(0, lambda: messagebox.showinfo("å®Œæˆ", "æœªæ‰¾åˆ°â€œå·¥å‚ç›´å‘â€çš„æ•°æ®è¡Œï¼ˆæ²¡æœ‰è¾“å‡ºæ–‡ä»¶ï¼‰ã€‚"))
                else:
                    pickup_cell, pickup_fname = parse_date(date_str)
                    out_base = os.path.join(outdir, f"ç›´å‘{pickup_fname[5:7]}{pickup_fname[8:10]}")
                    # --- æ‹†åˆ†å®Œæˆåï¼šå¯é€‰è‡ªåŠ¨ä¸‹è½½ FBA ç®±å”›ï¼ˆä¸å½±å“æ‹†åˆ†ç»“æœï¼‰ ---
                    try:
                        if bool(self.enable_fba_label_var.get()):
                            token = self.token_var.get().strip()
                            cookie = self._cookie_text.get("1.0", "end").strip() if hasattr(self, "_cookie_text") else ""
                            try:
                                cooldown_sec = int(float(self.fba_cooldown_var.get().strip() or FBA_PRINT_COOLDOWN_DEFAULT_SEC))
                            except Exception:
                                cooldown_sec = FBA_PRINT_COOLDOWN_DEFAULT_SEC
                            if not token or not cookie:
                                log_cb("âš ï¸ æœªå¡«å†™ token/cookieï¼Œè·³è¿‡ FBA ç®±å”›ä¸‹è½½ã€‚")
                            else:
                                for fp in outs:
                                    try:
                                        fba_download_labels_for_file(fp, token=token, cookie=cookie, log_cb=log_cb, cooldown_sec=cooldown_sec)
                                    except Exception as _ex:
                                        log_cb(f"âš ï¸ ç®±å”›ä¸‹è½½å¤±è´¥ï¼ˆ{os.path.basename(fp)}ï¼‰ï¼š{_ex}")
                    except Exception as _ex2:
                        log_cb(f"âš ï¸ ç®±å”›æ¨¡å—å¼‚å¸¸ï¼š{_ex2}")
                    self.after(0, lambda: messagebox.showinfo("å®Œæˆ", f"å·²ç”Ÿæˆ {len(outs)} ä»½æ–‡ä»¶ã€‚\nè¾“å‡ºç›®å½•ï¼š{out_base}"))
            except Exception as ex:
                # å…³é”®ä¿®å¤ï¼šä¸è¦åœ¨ lambda é‡Œç›´æ¥ç”¨ exï¼ˆPython3ä¼šæ¸…æ‰ except å˜é‡ï¼‰
                msg = str(ex)
                self.after(0, lambda m=msg: messagebox.showerror("å¤„ç†å¤±è´¥", m))
            finally:
                self.after(0, lambda: self.run_btn.config(state="normal"))

        threading.Thread(target=worker, daemon=True).start()

    def _load_config(self):
        try:
            if os.path.isfile(CONFIG_PATH):
                with open(CONFIG_PATH, "r", encoding="utf-8") as f:
                    cfg = json.load(f)
                self.file1_var.set(cfg.get("file1", ""))
                self.template_var.set(cfg.get("template", ""))
                self.cfg_var.set(cfg.get("cfgfile", ""))
                self.outdir_var.set(cfg.get("outdir", ""))
                self.date_var.set(cfg.get("date", ""))
                self.time_var.set(cfg.get("time_tag", ""))
                self.product_var.set(cfg.get("product_tag", ""))
                self.name_var.set(cfg.get("name", ""))
                self.split_var.set(bool(cfg.get("split_supplier_folder", True)))
                self.token_var.set(cfg.get("x_auth_token", ""))
                if hasattr(self, "_cookie_text"):
                    self._cookie_text.delete("1.0", "end")
                    self._cookie_text.insert("1.0", cfg.get("cookie", ""))
                self.acc_var.set(cfg.get("account", ""))
                self.pwd_var.set(cfg.get("password", ""))
                self.enable_fba_label_var.set(bool(cfg.get("enable_fba_label", True)))
                self.fba_cooldown_var.set(str(cfg.get("fba_cooldown_sec", FBA_PRINT_COOLDOWN_DEFAULT_SEC)))
            else:
                desktop = os.path.join(os.path.expanduser("~"), "Desktop")
                self.outdir_var.set(desktop if os.path.isdir(desktop) else os.path.expanduser("~"))
        except Exception:
            pass

    def _save_config(self):
        try:
            cfg = {
                "file1": self.file1_var.get().strip(),
                "template": self.template_var.get().strip(),
                "cfgfile": self.cfg_var.get().strip(),
                "outdir": self.outdir_var.get().strip(),
                "date": self.date_var.get().strip(),
                "time_tag": self.time_var.get().strip(),
                "product_tag": self.product_var.get().strip(),
                "name": self.name_var.get().strip(),
                "split_supplier_folder": bool(self.split_var.get()),
                "x_auth_token": self.token_var.get().strip(),
                "cookie": self._cookie_text.get("1.0", "end").strip() if hasattr(self, "_cookie_text") else "",
                "account": self.acc_var.get().strip(),
                "password": self.pwd_var.get().strip(),
                "enable_fba_label": bool(self.enable_fba_label_var.get()),
                "fba_cooldown_sec": self.fba_cooldown_var.get().strip(),
            }
            with open(CONFIG_PATH, "w", encoding="utf-8") as f:
                json.dump(cfg, f, ensure_ascii=False, indent=2)
        except Exception:
            pass

    def _on_close(self):
        self._save_config()
        self.destroy()


if __name__ == "__main__":
    App().mainloop()